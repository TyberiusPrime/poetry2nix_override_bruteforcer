{"info":{"author":"Christopher Flynn","author_email":"crf204@gmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Natural Language :: English","Programming Language :: Python :: 2","Programming Language :: Python :: 2.7","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.5","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Python :: Implementation :: CPython"],"description":"databricks-api\n==============\n\n**Please switch to the official Databricks SDK for Python (https://github.com/databricks/databricks-sdk-py) by running the following command:**\n\n.. code-block:: bash\n\n    pip install databricks-sdk\n\n\n|pypi| |pyversions|\n\n.. |pypi| image:: https://img.shields.io/pypi/v/databricks-api.svg\n    :target: https://pypi.python.org/pypi/databricks-api\n\n.. |pyversions| image:: https://img.shields.io/pypi/pyversions/databricks-api.svg\n    :target: https://pypi.python.org/pypi/databricks-api\n\n*[This documentation is auto-generated]*\n\nThis package provides a simplified interface for the Databricks REST API.\nThe interface is autogenerated on instantiation using the underlying client\nlibrary used in the official ``databricks-cli`` python package.\n\nInstall using\n\n.. code-block:: bash\n\n    pip install databricks-api\n    \n\nThe docs here describe the interface for version **0.17.0** of\nthe ``databricks-cli`` package for API version **2.0**.\n\nThe ``databricks-api`` package contains a ``DatabricksAPI`` class which provides\ninstance attributes for the ``databricks-cli`` ``ApiClient``, as well as each of\nthe available service instances. The attributes of a ``DatabricksAPI`` instance are:\n\n* DatabricksAPI.client *<databricks_cli.sdk.api_client.ApiClient>*\n* DatabricksAPI.jobs *<databricks_cli.sdk.service.JobsService>*\n* DatabricksAPI.cluster *<databricks_cli.sdk.service.ClusterService>*\n* DatabricksAPI.policy *<databricks_cli.sdk.service.PolicyService>*\n* DatabricksAPI.managed_library *<databricks_cli.sdk.service.ManagedLibraryService>*\n* DatabricksAPI.dbfs *<databricks_cli.sdk.service.DbfsService>*\n* DatabricksAPI.workspace *<databricks_cli.sdk.service.WorkspaceService>*\n* DatabricksAPI.secret *<databricks_cli.sdk.service.SecretService>*\n* DatabricksAPI.groups *<databricks_cli.sdk.service.GroupsService>*\n* DatabricksAPI.token *<databricks_cli.sdk.service.TokenService>*\n* DatabricksAPI.instance_pool *<databricks_cli.sdk.service.InstancePoolService>*\n* DatabricksAPI.delta_pipelines *<databricks_cli.sdk.service.DeltaPipelinesService>*\n* DatabricksAPI.repos *<databricks_cli.sdk.service.ReposService>*\n\nTo instantiate the client, provide the databricks host and either a token or\nuser and password. Also shown is the full signature of the\nunderlying ``ApiClient.__init__``\n\n.. code-block:: python\n\n    from databricks_api import DatabricksAPI\n\n    # Provide a host and token\n    db = DatabricksAPI(\n        host=\"example.cloud.databricks.com\",\n        token=\"dpapi123...\"\n    )\n\n    # OR a host and user and password\n    db = DatabricksAPI(\n        host=\"example.cloud.databricks.com\",\n        user=\"me@example.com\",\n        password=\"password\"\n    )\n\n    # Full __init__ signature\n    db = DatabricksAPI(\n        user=None,\n        password=None,\n        host=None,\n        token=None,\n        api_version='2.0',\n        default_headers={},\n        verify=True,\n        command_name='',\n        jobs_api_version=None\n    )\n\nRefer to the `official documentation <https://docs.databricks.com/api/index.html>`_\non the functionality and required arguments of each method below.\n\nEach of the service instance attributes provides the following public methods:\n\nDatabricksAPI.jobs\n------------------\n\n.. code-block:: python\n\n    db.jobs.cancel_run(\n        run_id,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.create_job(\n        name=None,\n        existing_cluster_id=None,\n        new_cluster=None,\n        libraries=None,\n        email_notifications=None,\n        timeout_seconds=None,\n        max_retries=None,\n        min_retry_interval_millis=None,\n        retry_on_timeout=None,\n        schedule=None,\n        notebook_task=None,\n        spark_jar_task=None,\n        spark_python_task=None,\n        spark_submit_task=None,\n        max_concurrent_runs=None,\n        tasks=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.delete_job(\n        job_id,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.delete_run(\n        run_id=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.export_run(\n        run_id,\n        views_to_export=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.get_job(\n        job_id,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.get_run(\n        run_id=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.get_run_output(\n        run_id,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.list_jobs(\n        job_type=None,\n        expand_tasks=None,\n        limit=None,\n        offset=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.list_runs(\n        job_id=None,\n        active_only=None,\n        completed_only=None,\n        offset=None,\n        limit=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.reset_job(\n        job_id,\n        new_settings,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.run_now(\n        job_id=None,\n        jar_params=None,\n        notebook_params=None,\n        python_params=None,\n        spark_submit_params=None,\n        python_named_params=None,\n        idempotency_token=None,\n        headers=None,\n        version=None,\n    )\n\n    db.jobs.submit_run(\n        run_name=None,\n        existing_cluster_id=None,\n        new_cluster=None,\n        libraries=None,\n        notebook_task=None,\n        spark_jar_task=None,\n        spark_python_task=None,\n        spark_submit_task=None,\n        timeout_seconds=None,\n        tasks=None,\n        headers=None,\n        version=None,\n    )\n\n\nDatabricksAPI.cluster\n---------------------\n\n.. code-block:: python\n\n    db.cluster.create_cluster(\n        num_workers=None,\n        autoscale=None,\n        cluster_name=None,\n        spark_version=None,\n        spark_conf=None,\n        aws_attributes=None,\n        node_type_id=None,\n        driver_node_type_id=None,\n        ssh_public_keys=None,\n        custom_tags=None,\n        cluster_log_conf=None,\n        spark_env_vars=None,\n        autotermination_minutes=None,\n        enable_elastic_disk=None,\n        cluster_source=None,\n        instance_pool_id=None,\n        headers=None,\n    )\n\n    db.cluster.delete_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n    db.cluster.edit_cluster(\n        cluster_id,\n        num_workers=None,\n        autoscale=None,\n        cluster_name=None,\n        spark_version=None,\n        spark_conf=None,\n        aws_attributes=None,\n        node_type_id=None,\n        driver_node_type_id=None,\n        ssh_public_keys=None,\n        custom_tags=None,\n        cluster_log_conf=None,\n        spark_env_vars=None,\n        autotermination_minutes=None,\n        enable_elastic_disk=None,\n        cluster_source=None,\n        instance_pool_id=None,\n        headers=None,\n    )\n\n    db.cluster.get_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n    db.cluster.get_events(\n        cluster_id,\n        start_time=None,\n        end_time=None,\n        order=None,\n        event_types=None,\n        offset=None,\n        limit=None,\n        headers=None,\n    )\n\n    db.cluster.list_available_zones(headers=None)\n\n    db.cluster.list_clusters(headers=None)\n\n    db.cluster.list_node_types(headers=None)\n\n    db.cluster.list_spark_versions(headers=None)\n\n    db.cluster.permanent_delete_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n    db.cluster.pin_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n    db.cluster.resize_cluster(\n        cluster_id,\n        num_workers=None,\n        autoscale=None,\n        headers=None,\n    )\n\n    db.cluster.restart_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n    db.cluster.start_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n    db.cluster.unpin_cluster(\n        cluster_id,\n        headers=None,\n    )\n\n\nDatabricksAPI.policy\n--------------------\n\n.. code-block:: python\n\n    db.policy.create_policy(\n        policy_name,\n        definition,\n        headers=None,\n    )\n\n    db.policy.delete_policy(\n        policy_id,\n        headers=None,\n    )\n\n    db.policy.edit_policy(\n        policy_id,\n        policy_name,\n        definition,\n        headers=None,\n    )\n\n    db.policy.get_policy(\n        policy_id,\n        headers=None,\n    )\n\n    db.policy.list_policies(headers=None)\n\n\nDatabricksAPI.managed_library\n-----------------------------\n\n.. code-block:: python\n\n    db.managed_library.all_cluster_statuses(headers=None)\n\n    db.managed_library.cluster_status(\n        cluster_id,\n        headers=None,\n    )\n\n    db.managed_library.install_libraries(\n        cluster_id,\n        libraries=None,\n        headers=None,\n    )\n\n    db.managed_library.uninstall_libraries(\n        cluster_id,\n        libraries=None,\n        headers=None,\n    )\n\n\nDatabricksAPI.dbfs\n------------------\n\n.. code-block:: python\n\n    db.dbfs.add_block(\n        handle,\n        data,\n        headers=None,\n    )\n\n    db.dbfs.add_block_test(\n        handle,\n        data,\n        headers=None,\n    )\n\n    db.dbfs.close(\n        handle,\n        headers=None,\n    )\n\n    db.dbfs.close_test(\n        handle,\n        headers=None,\n    )\n\n    db.dbfs.create(\n        path,\n        overwrite=None,\n        headers=None,\n    )\n\n    db.dbfs.create_test(\n        path,\n        overwrite=None,\n        headers=None,\n    )\n\n    db.dbfs.delete(\n        path,\n        recursive=None,\n        headers=None,\n    )\n\n    db.dbfs.delete_test(\n        path,\n        recursive=None,\n        headers=None,\n    )\n\n    db.dbfs.get_status(\n        path,\n        headers=None,\n    )\n\n    db.dbfs.get_status_test(\n        path,\n        headers=None,\n    )\n\n    db.dbfs.list(\n        path,\n        headers=None,\n    )\n\n    db.dbfs.list_test(\n        path,\n        headers=None,\n    )\n\n    db.dbfs.mkdirs(\n        path,\n        headers=None,\n    )\n\n    db.dbfs.mkdirs_test(\n        path,\n        headers=None,\n    )\n\n    db.dbfs.move(\n        source_path,\n        destination_path,\n        headers=None,\n    )\n\n    db.dbfs.move_test(\n        source_path,\n        destination_path,\n        headers=None,\n    )\n\n    db.dbfs.put(\n        path,\n        contents=None,\n        overwrite=None,\n        headers=None,\n        src_path=None,\n    )\n\n    db.dbfs.put_test(\n        path,\n        contents=None,\n        overwrite=None,\n        headers=None,\n        src_path=None,\n    )\n\n    db.dbfs.read(\n        path,\n        offset=None,\n        length=None,\n        headers=None,\n    )\n\n    db.dbfs.read_test(\n        path,\n        offset=None,\n        length=None,\n        headers=None,\n    )\n\n\nDatabricksAPI.workspace\n-----------------------\n\n.. code-block:: python\n\n    db.workspace.delete(\n        path,\n        recursive=None,\n        headers=None,\n    )\n\n    db.workspace.export_workspace(\n        path,\n        format=None,\n        direct_download=None,\n        headers=None,\n    )\n\n    db.workspace.get_status(\n        path,\n        headers=None,\n    )\n\n    db.workspace.import_workspace(\n        path,\n        format=None,\n        language=None,\n        content=None,\n        overwrite=None,\n        headers=None,\n    )\n\n    db.workspace.list(\n        path,\n        headers=None,\n    )\n\n    db.workspace.mkdirs(\n        path,\n        headers=None,\n    )\n\n\nDatabricksAPI.secret\n--------------------\n\n.. code-block:: python\n\n    db.secret.create_scope(\n        scope,\n        initial_manage_principal=None,\n        scope_backend_type=None,\n        backend_azure_keyvault=None,\n        headers=None,\n    )\n\n    db.secret.delete_acl(\n        scope,\n        principal,\n        headers=None,\n    )\n\n    db.secret.delete_scope(\n        scope,\n        headers=None,\n    )\n\n    db.secret.delete_secret(\n        scope,\n        key,\n        headers=None,\n    )\n\n    db.secret.get_acl(\n        scope,\n        principal,\n        headers=None,\n    )\n\n    db.secret.list_acls(\n        scope,\n        headers=None,\n    )\n\n    db.secret.list_scopes(headers=None)\n\n    db.secret.list_secrets(\n        scope,\n        headers=None,\n    )\n\n    db.secret.put_acl(\n        scope,\n        principal,\n        permission,\n        headers=None,\n    )\n\n    db.secret.put_secret(\n        scope,\n        key,\n        string_value=None,\n        bytes_value=None,\n        headers=None,\n    )\n\n\nDatabricksAPI.groups\n--------------------\n\n.. code-block:: python\n\n    db.groups.add_to_group(\n        parent_name,\n        user_name=None,\n        group_name=None,\n        headers=None,\n    )\n\n    db.groups.create_group(\n        group_name,\n        headers=None,\n    )\n\n    db.groups.get_group_members(\n        group_name,\n        headers=None,\n    )\n\n    db.groups.get_groups(headers=None)\n\n    db.groups.get_groups_for_principal(\n        user_name=None,\n        group_name=None,\n        headers=None,\n    )\n\n    db.groups.remove_from_group(\n        parent_name,\n        user_name=None,\n        group_name=None,\n        headers=None,\n    )\n\n    db.groups.remove_group(\n        group_name,\n        headers=None,\n    )\n\n\nDatabricksAPI.token\n-------------------\n\n.. code-block:: python\n\n    db.token.create_token(\n        lifetime_seconds=None,\n        comment=None,\n        headers=None,\n    )\n\n    db.token.list_tokens(headers=None)\n\n    db.token.revoke_token(\n        token_id,\n        headers=None,\n    )\n\n\nDatabricksAPI.instance_pool\n---------------------------\n\n.. code-block:: python\n\n    db.instance_pool.create_instance_pool(\n        instance_pool_name=None,\n        min_idle_instances=None,\n        max_capacity=None,\n        aws_attributes=None,\n        node_type_id=None,\n        custom_tags=None,\n        idle_instance_autotermination_minutes=None,\n        enable_elastic_disk=None,\n        disk_spec=None,\n        preloaded_spark_versions=None,\n        headers=None,\n    )\n\n    db.instance_pool.delete_instance_pool(\n        instance_pool_id=None,\n        headers=None,\n    )\n\n    db.instance_pool.edit_instance_pool(\n        instance_pool_id,\n        instance_pool_name=None,\n        min_idle_instances=None,\n        max_capacity=None,\n        aws_attributes=None,\n        node_type_id=None,\n        custom_tags=None,\n        idle_instance_autotermination_minutes=None,\n        enable_elastic_disk=None,\n        disk_spec=None,\n        preloaded_spark_versions=None,\n        headers=None,\n    )\n\n    db.instance_pool.get_instance_pool(\n        instance_pool_id=None,\n        headers=None,\n    )\n\n    db.instance_pool.list_instance_pools(headers=None)\n\n\nDatabricksAPI.delta_pipelines\n-----------------------------\n\n.. code-block:: python\n\n    db.delta_pipelines.create(\n        id=None,\n        name=None,\n        storage=None,\n        configuration=None,\n        clusters=None,\n        libraries=None,\n        trigger=None,\n        filters=None,\n        allow_duplicate_names=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.delete(\n        pipeline_id=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.deploy(\n        pipeline_id=None,\n        id=None,\n        name=None,\n        storage=None,\n        configuration=None,\n        clusters=None,\n        libraries=None,\n        trigger=None,\n        filters=None,\n        allow_duplicate_names=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.get(\n        pipeline_id=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.list(\n        pagination=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.reset(\n        pipeline_id=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.run(\n        pipeline_id=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.start_update(\n        pipeline_id=None,\n        full_refresh=None,\n        headers=None,\n    )\n\n    db.delta_pipelines.stop(\n        pipeline_id=None,\n        headers=None,\n    )\n\n\nDatabricksAPI.repos\n-------------------\n\n.. code-block:: python\n\n    db.repos.create_repo(\n        url,\n        provider,\n        path=None,\n        headers=None,\n    )\n\n    db.repos.delete_repo(\n        id,\n        headers=None,\n    )\n\n    db.repos.get_repo(\n        id,\n        headers=None,\n    )\n\n    db.repos.list_repos(\n        path_prefix=None,\n        next_page_token=None,\n        headers=None,\n    )\n\n    db.repos.update_repo(\n        id,\n        branch=None,\n        tag=None,\n        headers=None,\n    )\n\n\n","description_content_type":"text/x-rst","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/crflynn/databricks-api","keywords":"databricks,api,client","license":"MIT","maintainer":"","maintainer_email":"","name":"databricks-api","package_url":"https://pypi.org/project/databricks-api/","platform":null,"project_url":"https://pypi.org/project/databricks-api/","project_urls":{"Homepage":"https://github.com/crflynn/databricks-api","Repository":"https://github.com/crflynn/databricks-api"},"provides_extra":null,"release_url":"https://pypi.org/project/databricks-api/0.9.0/","requires_dist":["databricks-cli"],"requires_python":">=3.6,<4.0","summary":"Databricks API client auto-generated from the official databricks-cli package","version":"0.9.0","yanked":false,"yanked_reason":null},"last_serial":18428253,"releases":{"0.1.0":[{"comment_text":"","digests":{"blake2b_256":"3052f2f6abd00d59059d0f0733a2a1b5088b1ce3bc4a2eafd8ff55d032c245de","md5":"db7ce28762263b40eca51e1d9eb42a55","sha256":"276ab4a26b8aa60d9a86c5fb305431c133acac4cc8e4188fbaecbc9e46636a68"},"downloads":-1,"filename":"databricks_api-0.1.0-py2.py3-none-any.whl","has_sig":false,"md5_digest":"db7ce28762263b40eca51e1d9eb42a55","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":null,"size":4269,"upload_time":"2018-10-11T02:08:33","upload_time_iso_8601":"2018-10-11T02:08:33.345746Z","url":"https://files.pythonhosted.org/packages/30/52/f2f6abd00d59059d0f0733a2a1b5088b1ce3bc4a2eafd8ff55d032c245de/databricks_api-0.1.0-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9d1c2862a98a6541043fb5d3105456d05789c318f23aff5753bd7244ccf2cebf","md5":"a058889dfcb13c3c93265a9a3320d724","sha256":"e9796bea26f3236b9d4d82781292ce52ca7f67d81841c61c077301e05c6bd7cd"},"downloads":-1,"filename":"databricks-api-0.1.0.tar.gz","has_sig":false,"md5_digest":"a058889dfcb13c3c93265a9a3320d724","packagetype":"sdist","python_version":"source","requires_python":null,"size":5464,"upload_time":"2018-10-11T02:08:34","upload_time_iso_8601":"2018-10-11T02:08:34.421378Z","url":"https://files.pythonhosted.org/packages/9d/1c/2862a98a6541043fb5d3105456d05789c318f23aff5753bd7244ccf2cebf/databricks-api-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"0.2.0":[{"comment_text":"","digests":{"blake2b_256":"77683775cd41db067d77710a9877e9fb61c82217e09d20f9408fb8c31da045b8","md5":"b56a24549841bea146b7560cfbc872b9","sha256":"54c10540c0c056447791a7b473c6285eaa33541d1b11e2435cebc28810a94d7e"},"downloads":-1,"filename":"databricks_api-0.2.0-py2.py3-none-any.whl","has_sig":false,"md5_digest":"b56a24549841bea146b7560cfbc872b9","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":5480,"upload_time":"2019-08-17T23:20:44","upload_time_iso_8601":"2019-08-17T23:20:44.378774Z","url":"https://files.pythonhosted.org/packages/77/68/3775cd41db067d77710a9877e9fb61c82217e09d20f9408fb8c31da045b8/databricks_api-0.2.0-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b901b72afd655bb93bef4a48605624d5b1605340ddbb500396c4e65f8d5f5a9f","md5":"5f9d1a95043eb32e15c417e720ca393e","sha256":"6c4397cf790129947df1654d3eb2d96c2560defa0de1ff27bf8ce1fc353ec49b"},"downloads":-1,"filename":"databricks_api-0.2.0.tar.gz","has_sig":false,"md5_digest":"5f9d1a95043eb32e15c417e720ca393e","packagetype":"sdist","python_version":"source","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":6919,"upload_time":"2019-08-17T23:20:46","upload_time_iso_8601":"2019-08-17T23:20:46.763785Z","url":"https://files.pythonhosted.org/packages/b9/01/b72afd655bb93bef4a48605624d5b1605340ddbb500396c4e65f8d5f5a9f/databricks_api-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"0.3.0":[{"comment_text":"","digests":{"blake2b_256":"40c702501c2494ad160c007aadac18c7dea2e83c9e0f4bc8137b45e3a4bc11a2","md5":"00121d957e06d4720076560a37ccf686","sha256":"8f637288d05b3d214ea1636bb31d6423c751d85fdccd25fd0d0c86657e7c0abc"},"downloads":-1,"filename":"databricks_api-0.3.0-py2.py3-none-any.whl","has_sig":false,"md5_digest":"00121d957e06d4720076560a37ccf686","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":5718,"upload_time":"2019-08-29T02:04:35","upload_time_iso_8601":"2019-08-29T02:04:35.896386Z","url":"https://files.pythonhosted.org/packages/40/c7/02501c2494ad160c007aadac18c7dea2e83c9e0f4bc8137b45e3a4bc11a2/databricks_api-0.3.0-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3ec142d380a153910f8becd19840c9a27166006ecf84048fe92a2e16e98c1de1","md5":"2b50af6ce0dccaaea11da4ef6d52044f","sha256":"3e37422b2e52b1d8aa68e3ce36034d86313170f56fac11f88295713d450dbd99"},"downloads":-1,"filename":"databricks_api-0.3.0.tar.gz","has_sig":false,"md5_digest":"2b50af6ce0dccaaea11da4ef6d52044f","packagetype":"sdist","python_version":"source","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":7234,"upload_time":"2019-08-29T02:04:38","upload_time_iso_8601":"2019-08-29T02:04:38.156563Z","url":"https://files.pythonhosted.org/packages/3e/c1/42d380a153910f8becd19840c9a27166006ecf84048fe92a2e16e98c1de1/databricks_api-0.3.0.tar.gz","yanked":false,"yanked_reason":null}],"0.4.0":[{"comment_text":"","digests":{"blake2b_256":"cba50d543d465e8457ab5b2ef4a250d174ae9b18f386a1bf3cb075808546acc1","md5":"85fa726e29371c9ddcb09ae48ea1e3d9","sha256":"7a0df5a6ab535b03e18705d3aab7ee78e1628a5f55f22ba161c55869f406ee87"},"downloads":-1,"filename":"databricks_api-0.4.0-py2.py3-none-any.whl","has_sig":false,"md5_digest":"85fa726e29371c9ddcb09ae48ea1e3d9","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":5782,"upload_time":"2020-04-01T23:44:34","upload_time_iso_8601":"2020-04-01T23:44:34.044465Z","url":"https://files.pythonhosted.org/packages/cb/a5/0d543d465e8457ab5b2ef4a250d174ae9b18f386a1bf3cb075808546acc1/databricks_api-0.4.0-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"edc2c6f73b0e05fb84e8dd941485efcc4f64bae9eb696eb7c23cbb3bd307f555","md5":"0fd79cc6981f030f265ae0d7b3d1de33","sha256":"c7b530fc2788bad2298e57a7e6e8ca2fb0fb5f327f59e5af224019e0eaf141d6"},"downloads":-1,"filename":"databricks_api-0.4.0.tar.gz","has_sig":false,"md5_digest":"0fd79cc6981f030f265ae0d7b3d1de33","packagetype":"sdist","python_version":"source","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":7366,"upload_time":"2020-04-01T23:44:35","upload_time_iso_8601":"2020-04-01T23:44:35.933678Z","url":"https://files.pythonhosted.org/packages/ed/c2/c6f73b0e05fb84e8dd941485efcc4f64bae9eb696eb7c23cbb3bd307f555/databricks_api-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"0.5.0":[{"comment_text":"","digests":{"blake2b_256":"6a6433623f30db8b380b7252b2ca7fc5132e146cf35fcffadeb9ef9820814de6","md5":"6357c3667eeb81563fb45c3e0160b8b1","sha256":"ad34e7a1381229cd055d83f6f310a9104779b8e5cac500bfe4f6ad570eb2ce65"},"downloads":-1,"filename":"databricks_api-0.5.0-py2.py3-none-any.whl","has_sig":false,"md5_digest":"6357c3667eeb81563fb45c3e0160b8b1","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":6084,"upload_time":"2020-09-23T22:56:53","upload_time_iso_8601":"2020-09-23T22:56:53.373166Z","url":"https://files.pythonhosted.org/packages/6a/64/33623f30db8b380b7252b2ca7fc5132e146cf35fcffadeb9ef9820814de6/databricks_api-0.5.0-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"6ea8a0ffe9a0406007ff8a96be70b0f243bd290c61b2f86315d0c220098bbc9d","md5":"0ff8272fe04b895496f9b562ff85f6b0","sha256":"7880dc3e4a3685dd68fb13ccf506093cce3f1f73f566c18fdc30f543d74ef251"},"downloads":-1,"filename":"databricks_api-0.5.0.tar.gz","has_sig":false,"md5_digest":"0ff8272fe04b895496f9b562ff85f6b0","packagetype":"sdist","python_version":"source","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":8100,"upload_time":"2020-09-23T22:56:55","upload_time_iso_8601":"2020-09-23T22:56:55.257830Z","url":"https://files.pythonhosted.org/packages/6e/a8/a0ffe9a0406007ff8a96be70b0f243bd290c61b2f86315d0c220098bbc9d/databricks_api-0.5.0.tar.gz","yanked":false,"yanked_reason":null}],"0.5.1":[{"comment_text":"","digests":{"blake2b_256":"cf820d10153da8b7e7634d5e90e9bb983a9d890dd58ecd2be4d8029d269b9560","md5":"291b0399c6b7cafe8b651325a3039f69","sha256":"b7e5e55a4f63bd6bc1e958b441aa762a28d9796966f4a7807fb867c86fb945b8"},"downloads":-1,"filename":"databricks_api-0.5.1-py2.py3-none-any.whl","has_sig":false,"md5_digest":"291b0399c6b7cafe8b651325a3039f69","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":6079,"upload_time":"2020-09-23T23:00:30","upload_time_iso_8601":"2020-09-23T23:00:30.774205Z","url":"https://files.pythonhosted.org/packages/cf/82/0d10153da8b7e7634d5e90e9bb983a9d890dd58ecd2be4d8029d269b9560/databricks_api-0.5.1-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"14fc7272e92c22911dde5d1aa11fa45c3335958f062a9eedd03f7e30548842df","md5":"a6366986fb29d2afbc6dd9de93a7b616","sha256":"d8a416cdcd6aba5ac6370e205d4b3781137b3557fa9d66225266a942ceaedc2c"},"downloads":-1,"filename":"databricks_api-0.5.1.tar.gz","has_sig":false,"md5_digest":"a6366986fb29d2afbc6dd9de93a7b616","packagetype":"sdist","python_version":"source","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":8085,"upload_time":"2020-09-23T23:00:32","upload_time_iso_8601":"2020-09-23T23:00:32.375252Z","url":"https://files.pythonhosted.org/packages/14/fc/7272e92c22911dde5d1aa11fa45c3335958f062a9eedd03f7e30548842df/databricks_api-0.5.1.tar.gz","yanked":false,"yanked_reason":null}],"0.6.0":[{"comment_text":"","digests":{"blake2b_256":"afa6208cac51a21a6e5d308b10d3a2a2b4d2552c87326d33c6a371fb34e94f5f","md5":"b99acd166f8697279e873db1f34d1b04","sha256":"5ed697f59c6c3c09bd649f8cfaa1345d5e273de093b968b2542d9f7c8ef348de"},"downloads":-1,"filename":"databricks_api-0.6.0-py2.py3-none-any.whl","has_sig":false,"md5_digest":"b99acd166f8697279e873db1f34d1b04","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":7122,"upload_time":"2020-11-17T15:40:46","upload_time_iso_8601":"2020-11-17T15:40:46.681004Z","url":"https://files.pythonhosted.org/packages/af/a6/208cac51a21a6e5d308b10d3a2a2b4d2552c87326d33c6a371fb34e94f5f/databricks_api-0.6.0-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"6022293ee41b6aee24edb5eb44bc3fa2c0c2fd95c81dc97abcba6de824393ea3","md5":"af75992351bac2698fcf44d9b2c33b2f","sha256":"4b11c544755e714c6e5d4d18ebe3e936e41eb15b7d6374a49c3102d92ee847ea"},"downloads":-1,"filename":"databricks_api-0.6.0.tar.gz","has_sig":false,"md5_digest":"af75992351bac2698fcf44d9b2c33b2f","packagetype":"sdist","python_version":"source","requires_python":">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*","size":8755,"upload_time":"2020-11-17T15:40:48","upload_time_iso_8601":"2020-11-17T15:40:48.743375Z","url":"https://files.pythonhosted.org/packages/60/22/293ee41b6aee24edb5eb44bc3fa2c0c2fd95c81dc97abcba6de824393ea3/databricks_api-0.6.0.tar.gz","yanked":false,"yanked_reason":null}],"0.7.0":[{"comment_text":"","digests":{"blake2b_256":"4dd4ff4b0522ec9fc8b4575a08f661e4f452637f6eac784205b4f7d6ef717845","md5":"bdbd4680090066e08677a2b0b321578b","sha256":"a4718b0dd16cd4b9477e879e7fdf4741b9ae2ae14ffb1ba3dcf8392d8c191869"},"downloads":-1,"filename":"databricks_api-0.7.0-py3-none-any.whl","has_sig":false,"md5_digest":"bdbd4680090066e08677a2b0b321578b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6,<4.0","size":7265,"upload_time":"2021-11-22T02:19:54","upload_time_iso_8601":"2021-11-22T02:19:54.355385Z","url":"https://files.pythonhosted.org/packages/4d/d4/ff4b0522ec9fc8b4575a08f661e4f452637f6eac784205b4f7d6ef717845/databricks_api-0.7.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"72377ecdf94105a428a6d94930e163db288a9ff8422b625177f87ee3871bad8e","md5":"c2528180bf8de9054a662d5d1dad92ce","sha256":"48dfc3cae2bec87189332293d5ea90ce632ffaea8892ca58836b4c7da1da8d33"},"downloads":-1,"filename":"databricks_api-0.7.0.tar.gz","has_sig":false,"md5_digest":"c2528180bf8de9054a662d5d1dad92ce","packagetype":"sdist","python_version":"source","requires_python":">=3.6,<4.0","size":9849,"upload_time":"2021-11-22T02:19:56","upload_time_iso_8601":"2021-11-22T02:19:56.800994Z","url":"https://files.pythonhosted.org/packages/72/37/7ecdf94105a428a6d94930e163db288a9ff8422b625177f87ee3871bad8e/databricks_api-0.7.0.tar.gz","yanked":false,"yanked_reason":null}],"0.8.0":[{"comment_text":"","digests":{"blake2b_256":"c2690d7f361d655eda7dcaf0f3e41bd0e44c4c7dc41ae40911906723200a3883","md5":"8bcdca4a2d6ab3f26d069f5830f4fa35","sha256":"d689b9453f4772277f7df179a9e0abd0d5389590eb790cdfa14d714fd1541a9e"},"downloads":-1,"filename":"databricks_api-0.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"8bcdca4a2d6ab3f26d069f5830f4fa35","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6,<4.0","size":7189,"upload_time":"2022-06-17T21:40:00","upload_time_iso_8601":"2022-06-17T21:40:00.387022Z","url":"https://files.pythonhosted.org/packages/c2/69/0d7f361d655eda7dcaf0f3e41bd0e44c4c7dc41ae40911906723200a3883/databricks_api-0.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"675bfdaaa9ce90d45686b44ad048fe01cea6efab2fb8529f58df0380a540def6","md5":"0a5b1a95ea4915bc06f01dadeb36fdda","sha256":"49cbf99a4faef50b57ec79e74820bf9ff1f690090359b78eb82889f9962714e6"},"downloads":-1,"filename":"databricks_api-0.8.0.tar.gz","has_sig":false,"md5_digest":"0a5b1a95ea4915bc06f01dadeb36fdda","packagetype":"sdist","python_version":"source","requires_python":">=3.6,<4.0","size":10046,"upload_time":"2022-06-17T21:40:02","upload_time_iso_8601":"2022-06-17T21:40:02.669856Z","url":"https://files.pythonhosted.org/packages/67/5b/fdaaa9ce90d45686b44ad048fe01cea6efab2fb8529f58df0380a540def6/databricks_api-0.8.0.tar.gz","yanked":false,"yanked_reason":null}],"0.9.0":[{"comment_text":"","digests":{"blake2b_256":"d0cc6c3f9cd8b2b6c7a45c95b94d334bc51f1579d875bbfac0ecb8accdb2f756","md5":"bdd44cadb86c54e34fdadd535dcda1da","sha256":"51327fc1a06d9f4125a7a74d6764c3f1e99b6fb8f4b7f7cc178679b2c0d8ae5b"},"downloads":-1,"filename":"databricks_api-0.9.0-py3-none-any.whl","has_sig":false,"md5_digest":"bdd44cadb86c54e34fdadd535dcda1da","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6,<4.0","size":7428,"upload_time":"2023-06-08T16:37:30","upload_time_iso_8601":"2023-06-08T16:37:30.394202Z","url":"https://files.pythonhosted.org/packages/d0/cc/6c3f9cd8b2b6c7a45c95b94d334bc51f1579d875bbfac0ecb8accdb2f756/databricks_api-0.9.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"cc6b8e16b793108f0dc8d5d23516d26b377ef2eccea4e19a5b6a11893459ddd0","md5":"7a2bdbae09eca1fcda4caf1d7344a7ed","sha256":"40db26831ae37d2659d2700f4cb253615d895b6d440b99fb995aed51e67928f0"},"downloads":-1,"filename":"databricks_api-0.9.0.tar.gz","has_sig":false,"md5_digest":"7a2bdbae09eca1fcda4caf1d7344a7ed","packagetype":"sdist","python_version":"source","requires_python":">=3.6,<4.0","size":8398,"upload_time":"2023-06-08T16:37:33","upload_time_iso_8601":"2023-06-08T16:37:33.211950Z","url":"https://files.pythonhosted.org/packages/cc/6b/8e16b793108f0dc8d5d23516d26b377ef2eccea4e19a5b6a11893459ddd0/databricks_api-0.9.0.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"d0cc6c3f9cd8b2b6c7a45c95b94d334bc51f1579d875bbfac0ecb8accdb2f756","md5":"bdd44cadb86c54e34fdadd535dcda1da","sha256":"51327fc1a06d9f4125a7a74d6764c3f1e99b6fb8f4b7f7cc178679b2c0d8ae5b"},"downloads":-1,"filename":"databricks_api-0.9.0-py3-none-any.whl","has_sig":false,"md5_digest":"bdd44cadb86c54e34fdadd535dcda1da","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6,<4.0","size":7428,"upload_time":"2023-06-08T16:37:30","upload_time_iso_8601":"2023-06-08T16:37:30.394202Z","url":"https://files.pythonhosted.org/packages/d0/cc/6c3f9cd8b2b6c7a45c95b94d334bc51f1579d875bbfac0ecb8accdb2f756/databricks_api-0.9.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"cc6b8e16b793108f0dc8d5d23516d26b377ef2eccea4e19a5b6a11893459ddd0","md5":"7a2bdbae09eca1fcda4caf1d7344a7ed","sha256":"40db26831ae37d2659d2700f4cb253615d895b6d440b99fb995aed51e67928f0"},"downloads":-1,"filename":"databricks_api-0.9.0.tar.gz","has_sig":false,"md5_digest":"7a2bdbae09eca1fcda4caf1d7344a7ed","packagetype":"sdist","python_version":"source","requires_python":">=3.6,<4.0","size":8398,"upload_time":"2023-06-08T16:37:33","upload_time_iso_8601":"2023-06-08T16:37:33.211950Z","url":"https://files.pythonhosted.org/packages/cc/6b/8e16b793108f0dc8d5d23516d26b377ef2eccea4e19a5b6a11893459ddd0/databricks_api-0.9.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
