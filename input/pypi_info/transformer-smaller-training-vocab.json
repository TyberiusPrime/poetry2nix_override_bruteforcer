{"info":{"author":"Benedikt Fuchs","author_email":"benedikt.fuchs.staw@hotmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description":"# transformer-smaller-training-vocab\n\n[![PyPI version](https://badge.fury.io/py/transformer-smaller-training-vocab.svg)](https://badge.fury.io/py/transformer-smaller-training-vocab)\n[![GitHub Issues](https://img.shields.io/github/issues/helpmefindaname/transformer-smaller-training-vocab.svg)](https://github.com/helpmefindaname/transformer-smaller-training-vocab/issues)\n[![License: MIT](https://img.shields.io/badge/License-MIT-brightgreen.svg)](https://opensource.org/licenses/MIT)\n\n**Docs** are available [here](https://helpmefindaname.github.io/transformer-smaller-training-vocab)\n\n## Motivation\n\nHave you ever trained a transformer model and noticed that most tokens in the vocab are not used?\nLogically the token embeddings from those terms won't change, however they still take up memory and compute resources on your GPU.\nOne could assume that the embeddings are just a small part of the model and therefore aren't relevant, however looking at models like [xlm-roberta-large](https://huggingface.co/xlm-roberta-large) have 45.72% of parameters as \"word_embeddings\".\nBesides that, the gradient computation is done for the whole embedding weight, leading to gradient updates with very large amounts of 0s, eating a lot of memory, especially with state optimizers such as adam.\n\nTo reduce these inconveniences, this package provides a simple and easy to use way to\n* gather usage statistics of the vocabulary\n* temporary reduce the vocabulary to include no tokens that won't be used during training\n* fit in the tokens back in after the training is finished, so the full version can be saved.\n\n\n### Limitations\n\nThis library works fine, if you use any [FastTokenizer](https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)\nHowever if you want to use a `slow` tokenizer, it get's more tricky as huggingface-transformers has - per current date - no interface for overwriting the vocabulary in transformers.\nSo they require a custom implementation, currently the following tokenizers are supported:\n* XLMRobertaTokenizer\n* RobertaTokenizer\n* BertTokenizer\n\nIf you want to use a tokenizer that is not on the list, please [create an issue](https://github.com/helpmefindaname/transformer-smaller-training-vocab/issues) for it.\n\n## Quick Start\n\n### Requirements and Installation\n\nThe project is based on Transformers 4.1.0+, PyTorch 1.8+ and Python 3.8+\nThen, in your favorite virtual environment, simply run:\n\n```\npip install transformer-smaller-training-vocab\n```\n\n### Example Usage\n\nTo use more efficient training, it is enough to do the following changes to an abitary training script:\n\n```diff\n\n  model = ...\n  tokenizer = ...\n  raw_datasets = ...\n  ...\n\n+ with reduce_train_vocab(model=model, tokenizer=tokenizer, texts=get_texts_from_dataset(raw_datasets, key=\"text\")):\n      def preprocess_function(examples):\n          result = tokenizer(examples[\"text\"], padding=padding, max_length=max_seq_length, truncation=True)\n          result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n          return result\n    \n      raw_datasets = raw_datasets.map(\n          preprocess_function,\n          batched=True,\n      )\n    \n      trainer = Trainer(\n          model=model,\n          train_dataset=raw_datasets[\"train\"],\n          eval_dataset=raw_datasets[\"validation\"],\n          tokenizer=tokenizer,\n          ...\n      )\n    \n      trainer.train()\n\n+ trainer.save_model()  # save model at the end to contain the full vocab again.\n```\n\nDone! The Model will now be trained with only use the necessary parts of the token embeddings.\n\n## Impact\n\nHere is a table to document how much impact this technique has on training:\n\n| **Model** | **Dataset** | **Vocab reduction** | **Model size reduction** |\n|-----------|-------------|---------------------|--------------------------|\n| [xlm-roberta-large](https://huggingface.co/xlm-roberta-large) | CONLL 03 (en) |  93.13% | 42.58% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | CONLL 03 (en) | 93.13% | 64.31% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | CONLL 03 (en) | 43.64% | 08.97% |\n| [bert-base-uncased](https://huggingface.co/bert-base-uncased) | CONLL 03 (en) | 47.62% | 10.19% |\n| [bert-large-uncased](https://huggingface.co/roberta-base) | CONLL 03 (en) | 47.62% | 04.44% |\n| [roberta-base](https://huggingface.co/roberta-base) | CONLL 03 (en) | 58.39% | 18.08% |\n| [roberta-large](https://huggingface.co/roberta-large) | CONLL 03 (en) | 58.39% | 08.45% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | cola | 77.67% | 15.97% |\n| [roberta-base](https://huggingface.co/roberta-base) | cola | 86.08% | 26.66% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | cola | 97.79% | 67.52% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | mnli | 10.94% | 2.25% |\n| [roberta-base](https://huggingface.co/roberta-base) | mnli | 14.78% | 4.58% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | mnli | 88.83% | 61.34% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | mrpc | 49.93% | 10.27% |\n| [roberta-base](https://huggingface.co/roberta-base) | mrpc | 64.02% | 19.83% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | mrpc | 94.88% | 65.52% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | qnli | 8.62% | 1.77% |\n| [roberta-base](https://huggingface.co/roberta-base) | qnli | 17.64% | 5.46% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | qnli | 87.57% | 60.47% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | qqp | 7.69% | 1.58% |\n| [roberta-base](https://huggingface.co/roberta-base) | qqp | 5.91% | 1.83% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | qqp | 85.40% | 58.98% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | rte | 34.68% | 7.13% |\n| [roberta-base](https://huggingface.co/roberta-base) | rte | 50.49% | 15.64% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | rte | 93.10% | 64.29% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | sst2 | 62.39% | 12.83% |\n| [roberta-base](https://huggingface.co/roberta-base) | sst2 | 68.60% | 21.25% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | sst2 | 96.25% | 66.47% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | stsb | 51.35% | 10.56% |\n| [roberta-base](https://huggingface.co/roberta-base) | stsb | 64.37% | 19.93% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | stsb | 94.88% | 65.52% |\n| [bert-base-cased](https://huggingface.co/bert-base-cased) | wnli | 93.66% | 19.26% |\n| [roberta-base](https://huggingface.co/roberta-base) | wnli | 96.03% | 29.74% |\n| [xlm-roberta-base](https://huggingface.co/xlm-roberta-base) | wnli | 99.25% | 68.54% |\n\n\nNotice that while those reduced embeddings imply slightly less computation effort, those gains are neglectable, as the gradient computation for the parameters of transformer layers are dominant.\n","description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/helpmefindaname/transformer-smaller-training-vocab","keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"transformer-smaller-training-vocab","package_url":"https://pypi.org/project/transformer-smaller-training-vocab/","platform":null,"project_url":"https://pypi.org/project/transformer-smaller-training-vocab/","project_urls":{"Homepage":"https://github.com/helpmefindaname/transformer-smaller-training-vocab","Repository":"https://github.com/helpmefindaname/transformer-smaller-training-vocab"},"provides_extra":null,"release_url":"https://pypi.org/project/transformer-smaller-training-vocab/0.4.0/","requires_dist":["transformers[sentencepiece,torch]<5.0,>=4.1","torch!=2.0.1,<3.0.0,>=1.8.0","numpy<1.25.0; python_version >= \"3.8\" and python_version < \"3.9\"","numpy<2.0.0,>=1.21.0; python_version >= \"3.9\""],"requires_python":"<4.0,>=3.8","summary":"Temporary remove unused tokens during training to save ram and speed.","version":"0.4.0","yanked":false,"yanked_reason":null},"last_serial":22638304,"releases":{"0.1.0":[{"comment_text":"","digests":{"blake2b_256":"ac5970e2cc8c3e85de9c072bd9f5ef17e1724925e3b72ee640303a70697333b5","md5":"a895b38ae0c2e1ac3bd2c7a63724b4f4","sha256":"a00a6115ad989e997d2ac80b3a4ae284038dcbdbb8d8f0e7e47c25524975063f"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"a895b38ae0c2e1ac3bd2c7a63724b4f4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":12027,"upload_time":"2023-01-06T13:22:14","upload_time_iso_8601":"2023-01-06T13:22:14.538447Z","url":"https://files.pythonhosted.org/packages/ac/59/70e2cc8c3e85de9c072bd9f5ef17e1724925e3b72ee640303a70697333b5/transformer_smaller_training_vocab-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9919ba947b3abe2434de907bcb62363f960d68ef4b8f86a75fa72c880eef4e75","md5":"bf3b8dbc6a4cbaa982b79abd9bc8e691","sha256":"51657360eeab03dbc4368c8046f953237609e08592124e99b5feeee1ed8a7bec"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.1.0.tar.gz","has_sig":false,"md5_digest":"bf3b8dbc6a4cbaa982b79abd9bc8e691","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":10233,"upload_time":"2023-01-06T13:22:16","upload_time_iso_8601":"2023-01-06T13:22:16.117536Z","url":"https://files.pythonhosted.org/packages/99/19/ba947b3abe2434de907bcb62363f960d68ef4b8f86a75fa72c880eef4e75/transformer_smaller_training_vocab-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"0.1.7":[{"comment_text":"","digests":{"blake2b_256":"4a777434f393919610e7c76e78a5fe9e6be3418a85f2cf613e358883422f45a9","md5":"e9e17f977546a2a496aa2ba02550b053","sha256":"6f2f4791f03018aa0c815d686c9b1b66f0544c515522f06c11c1083479d3c085"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.1.7-py3-none-any.whl","has_sig":false,"md5_digest":"e9e17f977546a2a496aa2ba02550b053","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":11920,"upload_time":"2023-01-06T13:48:39","upload_time_iso_8601":"2023-01-06T13:48:39.995403Z","url":"https://files.pythonhosted.org/packages/4a/77/7434f393919610e7c76e78a5fe9e6be3418a85f2cf613e358883422f45a9/transformer_smaller_training_vocab-0.1.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3b63b04984ca7f390590cff709a7ba70d65648056470f3c95f5f47800923bf8f","md5":"502ca0995bc5b82e96c92b2bda27f321","sha256":"a2867f52dc3733c616314afdaabc3bb622e242488e1dbde08344a83eaa6b713b"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.1.7.tar.gz","has_sig":false,"md5_digest":"502ca0995bc5b82e96c92b2bda27f321","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":9856,"upload_time":"2023-01-06T13:48:41","upload_time_iso_8601":"2023-01-06T13:48:41.236535Z","url":"https://files.pythonhosted.org/packages/3b/63/b04984ca7f390590cff709a7ba70d65648056470f3c95f5f47800923bf8f/transformer_smaller_training_vocab-0.1.7.tar.gz","yanked":false,"yanked_reason":null}],"0.1.8":[{"comment_text":"","digests":{"blake2b_256":"cf131fc290bce19441b288df915d1577517ca015b1b43d7b0b8d120b94796566","md5":"318b1c3a6a47ffa85922471e9bdb7ea6","sha256":"7879a7fd633872e1ccd040d90e8bca35de064e644f15fa4a03e3e06edb5efd02"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.1.8-py3-none-any.whl","has_sig":false,"md5_digest":"318b1c3a6a47ffa85922471e9bdb7ea6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":11921,"upload_time":"2023-02-05T21:02:44","upload_time_iso_8601":"2023-02-05T21:02:44.623294Z","url":"https://files.pythonhosted.org/packages/cf/13/1fc290bce19441b288df915d1577517ca015b1b43d7b0b8d120b94796566/transformer_smaller_training_vocab-0.1.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"53a66afb0f61824083878fc7d0d12229297416b431cbb6e6eba0438735d1c80f","md5":"c60a370d3e14da549ce7b83bfcdf6ae1","sha256":"9f6e97d4d5d263291f6507cbc0de287d27c5fbbfad39f9907a08662e52304aed"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.1.8.tar.gz","has_sig":false,"md5_digest":"c60a370d3e14da549ce7b83bfcdf6ae1","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":9857,"upload_time":"2023-02-05T21:02:45","upload_time_iso_8601":"2023-02-05T21:02:45.717608Z","url":"https://files.pythonhosted.org/packages/53/a6/6afb0f61824083878fc7d0d12229297416b431cbb6e6eba0438735d1c80f/transformer_smaller_training_vocab-0.1.8.tar.gz","yanked":false,"yanked_reason":null}],"0.2.0":[{"comment_text":"","digests":{"blake2b_256":"6d84446df4f3bce5aa4e950237eee0ea051c5d8625658d3a03af043dccb82724","md5":"44169fe467979994e0d798ac4e9d87f2","sha256":"2f05a9d02b5c3ef39fd2881d0b604f8d0228652b67e06c46aac3968f35d60da2"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"44169fe467979994e0d798ac4e9d87f2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":12127,"upload_time":"2023-02-19T03:33:59","upload_time_iso_8601":"2023-02-19T03:33:59.022250Z","url":"https://files.pythonhosted.org/packages/6d/84/446df4f3bce5aa4e950237eee0ea051c5d8625658d3a03af043dccb82724/transformer_smaller_training_vocab-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2921d992cadb9a1731c91d26dcb4839821c15570cfa37699764a9229838e9ff1","md5":"f32f98d837d7bcaf4d1a7dbfe65dcb7b","sha256":"a87a2b3a0f345210f8d2a20dfb15d624f43d93e5cf35425faf99e0e6bdd5a709"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.0.tar.gz","has_sig":false,"md5_digest":"f32f98d837d7bcaf4d1a7dbfe65dcb7b","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":10029,"upload_time":"2023-02-19T03:34:00","upload_time_iso_8601":"2023-02-19T03:34:00.624723Z","url":"https://files.pythonhosted.org/packages/29/21/d992cadb9a1731c91d26dcb4839821c15570cfa37699764a9229838e9ff1/transformer_smaller_training_vocab-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"0.2.1":[{"comment_text":"","digests":{"blake2b_256":"80e52d34afa5fcd35a943cec2589b1c3a32de018256a729a84da0af292b1db87","md5":"5e11f106d2175f5f985590b600ccbe20","sha256":"a9788302d4a5de66d8189e13d9c62d86ff26e18feffc9acae841944f4515ff1f"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.1-py3-none-any.whl","has_sig":false,"md5_digest":"5e11f106d2175f5f985590b600ccbe20","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":12539,"upload_time":"2023-03-17T00:37:21","upload_time_iso_8601":"2023-03-17T00:37:21.663186Z","url":"https://files.pythonhosted.org/packages/80/e5/2d34afa5fcd35a943cec2589b1c3a32de018256a729a84da0af292b1db87/transformer_smaller_training_vocab-0.2.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1fcfb088d2b7f3614089306071a6e04a542a738a9e4899d2c6656d190031211a","md5":"f66809e405dec138193d6fcce8aa47a3","sha256":"bc55d434210e72098bd355eb0dc0fe3a26da7f9b300a95eb9b12ac33677e4dfe"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.1.tar.gz","has_sig":false,"md5_digest":"f66809e405dec138193d6fcce8aa47a3","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":10191,"upload_time":"2023-03-17T00:37:22","upload_time_iso_8601":"2023-03-17T00:37:22.852669Z","url":"https://files.pythonhosted.org/packages/1f/cf/b088d2b7f3614089306071a6e04a542a738a9e4899d2c6656d190031211a/transformer_smaller_training_vocab-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"0.2.2":[{"comment_text":"","digests":{"blake2b_256":"57edcb7f7aaea8c73c7e84c6ebbf28b2a54b0843e5a35e054e08c859b8b2c17d","md5":"0e4a7f6d8744062c9ec8969830689099","sha256":"e8370fc7f25f41c1cef9baee23d205d20662bb9034d2cd061aa7a261ef1ceb4a"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.2-py3-none-any.whl","has_sig":false,"md5_digest":"0e4a7f6d8744062c9ec8969830689099","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":12541,"upload_time":"2023-03-20T20:39:34","upload_time_iso_8601":"2023-03-20T20:39:34.194314Z","url":"https://files.pythonhosted.org/packages/57/ed/cb7f7aaea8c73c7e84c6ebbf28b2a54b0843e5a35e054e08c859b8b2c17d/transformer_smaller_training_vocab-0.2.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"01da023c5dc28f130fb846247894823924ba71a0537f55b4dc623f431cf24c81","md5":"650cae246e744084738d9d8da112507f","sha256":"8c7e589f338f797e81263656207418d7c81ea115a9060a6e96ac4eaa27b06d29"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.2.tar.gz","has_sig":false,"md5_digest":"650cae246e744084738d9d8da112507f","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":10182,"upload_time":"2023-03-20T20:39:35","upload_time_iso_8601":"2023-03-20T20:39:35.703190Z","url":"https://files.pythonhosted.org/packages/01/da/023c5dc28f130fb846247894823924ba71a0537f55b4dc623f431cf24c81/transformer_smaller_training_vocab-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"0.2.3":[{"comment_text":"","digests":{"blake2b_256":"0edca9c068e97a068190847c5f38b4652c48d19bd846111aad70e67e87f5eb81","md5":"d270660feac79fcb93892377e77a438a","sha256":"a666c1a7b8fb7b160835e72a4c2139f9897d569fa0e60a3bb796d0ce28c35524"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.3-py3-none-any.whl","has_sig":false,"md5_digest":"d270660feac79fcb93892377e77a438a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":12742,"upload_time":"2023-03-25T14:36:13","upload_time_iso_8601":"2023-03-25T14:36:13.379888Z","url":"https://files.pythonhosted.org/packages/0e/dc/a9c068e97a068190847c5f38b4652c48d19bd846111aad70e67e87f5eb81/transformer_smaller_training_vocab-0.2.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"cf48910d300aa0f6d7f9f28f6717c200300025c88754c0c6a522022e4eaabd1c","md5":"73e57f720fad50dad5bebb8dd6171cfd","sha256":"c8b7ce2b23c3aef5e289ea91a66ebf707d612875d70e2439085a7381c1655528"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.3.tar.gz","has_sig":false,"md5_digest":"73e57f720fad50dad5bebb8dd6171cfd","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":10325,"upload_time":"2023-03-25T14:36:15","upload_time_iso_8601":"2023-03-25T14:36:15.692257Z","url":"https://files.pythonhosted.org/packages/cf/48/910d300aa0f6d7f9f28f6717c200300025c88754c0c6a522022e4eaabd1c/transformer_smaller_training_vocab-0.2.3.tar.gz","yanked":false,"yanked_reason":null}],"0.2.4":[{"comment_text":"","digests":{"blake2b_256":"774bb262e5b47341c03ee7d757853d16dd068f595005af5fd0a9416a725d2052","md5":"54c70cb6a7abdffde2038fb7f3f52d74","sha256":"627204580a662201f4b9361bd94d7f0ea3a42eb1aed07383a7bafc8a5afee5b5"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.4-py3-none-any.whl","has_sig":false,"md5_digest":"54c70cb6a7abdffde2038fb7f3f52d74","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7,<4.0","size":13941,"upload_time":"2023-05-22T13:19:57","upload_time_iso_8601":"2023-05-22T13:19:57.163564Z","url":"https://files.pythonhosted.org/packages/77/4b/b262e5b47341c03ee7d757853d16dd068f595005af5fd0a9416a725d2052/transformer_smaller_training_vocab-0.2.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4f1b22119b86eefc153bae07298a19b24ab8b8f3bcb2c64f200a788d4beb8718","md5":"d7889c2f312b122c8d23f0cf8256228d","sha256":"48a27e00440744bc5cd96f3253f81f687070aaa279baf10baae495bd5772ecbb"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.2.4.tar.gz","has_sig":false,"md5_digest":"d7889c2f312b122c8d23f0cf8256228d","packagetype":"sdist","python_version":"source","requires_python":">=3.7,<4.0","size":11855,"upload_time":"2023-05-22T13:19:58","upload_time_iso_8601":"2023-05-22T13:19:58.820522Z","url":"https://files.pythonhosted.org/packages/4f/1b/22119b86eefc153bae07298a19b24ab8b8f3bcb2c64f200a788d4beb8718/transformer_smaller_training_vocab-0.2.4.tar.gz","yanked":false,"yanked_reason":null}],"0.3.1":[{"comment_text":"","digests":{"blake2b_256":"3292fbcbb135238cb935701f4fff1e467e75baa37726b8f4049912e294498a34","md5":"55f5778695eaa601583d879d579c0db7","sha256":"d7f4b006019bbe39f152f2633133eb8351fe335902382a7dbe0e750a3b7cc73f"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"55f5778695eaa601583d879d579c0db7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":14082,"upload_time":"2023-08-17T20:36:06","upload_time_iso_8601":"2023-08-17T20:36:06.603533Z","url":"https://files.pythonhosted.org/packages/32/92/fbcbb135238cb935701f4fff1e467e75baa37726b8f4049912e294498a34/transformer_smaller_training_vocab-0.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c310de095b918106f1e15c07b85ef0910cc99a841dd5712222484ec145eda0da","md5":"b0cffbad7d8c393421ab60be6cfa04ba","sha256":"677b22ef204af1d51d333b0db1222355048bf40cf710a4e4c7008604141f65d8"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.3.1.tar.gz","has_sig":false,"md5_digest":"b0cffbad7d8c393421ab60be6cfa04ba","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":12024,"upload_time":"2023-08-17T20:36:07","upload_time_iso_8601":"2023-08-17T20:36:07.934371Z","url":"https://files.pythonhosted.org/packages/c3/10/de095b918106f1e15c07b85ef0910cc99a841dd5712222484ec145eda0da/transformer_smaller_training_vocab-0.3.1.tar.gz","yanked":false,"yanked_reason":null}],"0.3.2":[{"comment_text":"","digests":{"blake2b_256":"625e4ba6cea4bff1eb107012f9b1f139e4f0a7e0005e59ab67b26d0cbc0a9e5f","md5":"2a1b5f036c8192cc75bbc5698a059a20","sha256":"1c6dc90339662f5afd908d228b6f5ed9acbc005ad9361cb79b4c24a70d582d4d"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.3.2-py3-none-any.whl","has_sig":false,"md5_digest":"2a1b5f036c8192cc75bbc5698a059a20","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":14080,"upload_time":"2023-09-18T13:47:25","upload_time_iso_8601":"2023-09-18T13:47:25.518282Z","url":"https://files.pythonhosted.org/packages/62/5e/4ba6cea4bff1eb107012f9b1f139e4f0a7e0005e59ab67b26d0cbc0a9e5f/transformer_smaller_training_vocab-0.3.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"db3dc8b94f7b2aebb922fadcb2f217b930066b9c4709f170598194fe2cc8b466","md5":"43f76ac5df7499ad04e55eff292c0df2","sha256":"cf490273711cfcb44e9e22c0a6118b55931ef6169647b1a8d8bd6a8d9f6a4398"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.3.2.tar.gz","has_sig":false,"md5_digest":"43f76ac5df7499ad04e55eff292c0df2","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":12023,"upload_time":"2023-09-18T13:47:26","upload_time_iso_8601":"2023-09-18T13:47:26.656521Z","url":"https://files.pythonhosted.org/packages/db/3d/c8b94f7b2aebb922fadcb2f217b930066b9c4709f170598194fe2cc8b466/transformer_smaller_training_vocab-0.3.2.tar.gz","yanked":false,"yanked_reason":null}],"0.3.3":[{"comment_text":"","digests":{"blake2b_256":"1acf37ccc33c7223707c92aed9d320a03fc80474ea81876b7a25096eab6fdd59","md5":"9ae0ac74283efe8732f411677dd656fa","sha256":"b0d41484063d01757c96fa8510810aff269f0596f6b6c0edd754f469209c9f26"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.3.3-py3-none-any.whl","has_sig":false,"md5_digest":"9ae0ac74283efe8732f411677dd656fa","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":14090,"upload_time":"2023-12-04T17:40:52","upload_time_iso_8601":"2023-12-04T17:40:52.414041Z","url":"https://files.pythonhosted.org/packages/1a/cf/37ccc33c7223707c92aed9d320a03fc80474ea81876b7a25096eab6fdd59/transformer_smaller_training_vocab-0.3.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"15df77d32294d8c910e86639ab975e9e1ce435b5930042d3fe280d1818260fee","md5":"96f82647ce2ac91892b54c91fe5e0d5a","sha256":"7843898842579fa80526bdd3a3696b55bdc7da4cfec095fbfa6b7153bf4ff972"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.3.3.tar.gz","has_sig":false,"md5_digest":"96f82647ce2ac91892b54c91fe5e0d5a","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":12022,"upload_time":"2023-12-04T17:40:53","upload_time_iso_8601":"2023-12-04T17:40:53.903261Z","url":"https://files.pythonhosted.org/packages/15/df/77d32294d8c910e86639ab975e9e1ce435b5930042d3fe280d1818260fee/transformer_smaller_training_vocab-0.3.3.tar.gz","yanked":false,"yanked_reason":null}],"0.4.0":[{"comment_text":"","digests":{"blake2b_256":"55c86a02e88256dc48faf3eae5732a94035f4ea0edd91d8224333693111921ba","md5":"1f6acea9e5eb9610d79b10df09e9b8a7","sha256":"01cb3d8f4818121172e1591a06c3149bf49bc18d6f6f269eb42d2c4ed155cfcc"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"1f6acea9e5eb9610d79b10df09e9b8a7","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":14120,"upload_time":"2024-04-05T15:31:14","upload_time_iso_8601":"2024-04-05T15:31:14.217453Z","url":"https://files.pythonhosted.org/packages/55/c8/6a02e88256dc48faf3eae5732a94035f4ea0edd91d8224333693111921ba/transformer_smaller_training_vocab-0.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"03285214ff2a93d9cccc55d0679cb8cbc3b9d52f1f07860c92841b16cfeb5026","md5":"3638dbf063f98f7ca986e5f312ae7867","sha256":"d7360ac084786f66f99ef16d621f34acbb0dce6d9a624525d1f7dc8b6c3a49f7"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.4.0.tar.gz","has_sig":false,"md5_digest":"3638dbf063f98f7ca986e5f312ae7867","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":12141,"upload_time":"2024-04-05T15:31:15","upload_time_iso_8601":"2024-04-05T15:31:15.336389Z","url":"https://files.pythonhosted.org/packages/03/28/5214ff2a93d9cccc55d0679cb8cbc3b9d52f1f07860c92841b16cfeb5026/transformer_smaller_training_vocab-0.4.0.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"55c86a02e88256dc48faf3eae5732a94035f4ea0edd91d8224333693111921ba","md5":"1f6acea9e5eb9610d79b10df09e9b8a7","sha256":"01cb3d8f4818121172e1591a06c3149bf49bc18d6f6f269eb42d2c4ed155cfcc"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"1f6acea9e5eb9610d79b10df09e9b8a7","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":14120,"upload_time":"2024-04-05T15:31:14","upload_time_iso_8601":"2024-04-05T15:31:14.217453Z","url":"https://files.pythonhosted.org/packages/55/c8/6a02e88256dc48faf3eae5732a94035f4ea0edd91d8224333693111921ba/transformer_smaller_training_vocab-0.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"03285214ff2a93d9cccc55d0679cb8cbc3b9d52f1f07860c92841b16cfeb5026","md5":"3638dbf063f98f7ca986e5f312ae7867","sha256":"d7360ac084786f66f99ef16d621f34acbb0dce6d9a624525d1f7dc8b6c3a49f7"},"downloads":-1,"filename":"transformer_smaller_training_vocab-0.4.0.tar.gz","has_sig":false,"md5_digest":"3638dbf063f98f7ca986e5f312ae7867","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":12141,"upload_time":"2024-04-05T15:31:15","upload_time_iso_8601":"2024-04-05T15:31:15.336389Z","url":"https://files.pythonhosted.org/packages/03/28/5214ff2a93d9cccc55d0679cb8cbc3b9d52f1f07860c92841b16cfeb5026/transformer_smaller_training_vocab-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
