{"info":{"author":"OpenAI","author_email":"","bugtrack_url":null,"classifiers":[],"description":"# Whisper\n\n[[Blog]](https://openai.com/blog/whisper)\n[[Paper]](https://arxiv.org/abs/2212.04356)\n[[Model card]](https://github.com/openai/whisper/blob/main/model-card.md)\n[[Colab example]](https://colab.research.google.com/github/openai/whisper/blob/master/notebooks/LibriSpeech.ipynb)\n\nWhisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.\n\n\n## Approach\n\n![Approach](https://raw.githubusercontent.com/openai/whisper/main/approach.png)\n\nA Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.\n\n\n## Setup\n\nWe used Python 3.9.9 and [PyTorch](https://pytorch.org/) 1.10.1 to train and test our models, but the codebase is expected to be compatible with Python 3.8-3.11 and recent PyTorch versions. The codebase also depends on a few Python packages, most notably [OpenAI's tiktoken](https://github.com/openai/tiktoken) for their fast tokenizer implementation. You can download and install (or update to) the latest release of Whisper with the following command:\n\n    pip install -U openai-whisper\n\nAlternatively, the following command will pull and install the latest commit from this repository, along with its Python dependencies:\n\n    pip install git+https://github.com/openai/whisper.git \n\nTo update the package to the latest version of this repository, please run:\n\n    pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n\nIt also requires the command-line tool [`ffmpeg`](https://ffmpeg.org/) to be installed on your system, which is available from most package managers:\n\n```bash\n# on Ubuntu or Debian\nsudo apt update && sudo apt install ffmpeg\n\n# on Arch Linux\nsudo pacman -S ffmpeg\n\n# on MacOS using Homebrew (https://brew.sh/)\nbrew install ffmpeg\n\n# on Windows using Chocolatey (https://chocolatey.org/)\nchoco install ffmpeg\n\n# on Windows using Scoop (https://scoop.sh/)\nscoop install ffmpeg\n```\n\nYou may need [`rust`](http://rust-lang.org) installed as well, in case [tiktoken](https://github.com/openai/tiktoken) does not provide a pre-built wheel for your platform. If you see installation errors during the `pip install` command above, please follow the [Getting started page](https://www.rust-lang.org/learn/get-started) to install Rust development environment. Additionally, you may need to configure the `PATH` environment variable, e.g. `export PATH=\"$HOME/.cargo/bin:$PATH\"`. If the installation fails with `No module named 'setuptools_rust'`, you need to install `setuptools_rust`, e.g. by running:\n\n```bash\npip install setuptools-rust\n```\n\n\n## Available models and languages\n\nThere are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. Below are the names of the available models and their approximate memory requirements and inference speed relative to the large model; actual speed may vary depending on many factors including the available hardware.\n\n|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n\nThe `.en` models for English-only applications tend to perform better, especially for the `tiny.en` and `base.en` models. We observed that the difference becomes less significant for the `small.en` and `medium.en` models.\n\nWhisper's performance varies widely depending on the language. The figure below shows a performance breakdown of `large-v3` and `large-v2` models by language, using WERs (word error rates) or CER (character error rates, shown in *Italic*) evaluated on the Common Voice 15 and Fleurs datasets. Additional WER/CER metrics corresponding to the other models and datasets can be found in Appendix D.1, D.2, and D.4 of [the paper](https://arxiv.org/abs/2212.04356), as well as the BLEU (Bilingual Evaluation Understudy) scores for translation in Appendix D.3.\n\n![WER breakdown by language](https://github.com/openai/whisper/assets/266841/f4619d66-1058-4005-8f67-a9d811b77c62)\n\n\n\n## Command-line usage\n\nThe following command will transcribe speech in audio files, using the `medium` model:\n\n    whisper audio.flac audio.mp3 audio.wav --model medium\n\nThe default setting (which selects the `small` model) works well for transcribing English. To transcribe an audio file containing non-English speech, you can specify the language using the `--language` option:\n\n    whisper japanese.wav --language Japanese\n\nAdding `--task translate` will translate the speech into English:\n\n    whisper japanese.wav --language Japanese --task translate\n\nRun the following to view all available options:\n\n    whisper --help\n\nSee [tokenizer.py](https://github.com/openai/whisper/blob/main/whisper/tokenizer.py) for the list of all available languages.\n\n\n## Python usage\n\nTranscription can also be performed within Python: \n\n```python\nimport whisper\n\nmodel = whisper.load_model(\"base\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])\n```\n\nInternally, the `transcribe()` method reads the entire file and processes the audio with a sliding 30-second window, performing autoregressive sequence-to-sequence predictions on each window.\n\nBelow is an example usage of `whisper.detect_language()` and `whisper.decode()` which provide lower-level access to the model.\n\n```python\nimport whisper\n\nmodel = whisper.load_model(\"base\")\n\n# load audio and pad/trim it to fit 30 seconds\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\n\n# make log-Mel spectrogram and move to the same device as the model\nmel = whisper.log_mel_spectrogram(audio).to(model.device)\n\n# detect the spoken language\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")\n\n# decode the audio\noptions = whisper.DecodingOptions()\nresult = whisper.decode(model, mel, options)\n\n# print the recognized text\nprint(result.text)\n```\n\n## More examples\n\nPlease use the [ðŸ™Œ Show and tell](https://github.com/openai/whisper/discussions/categories/show-and-tell) category in Discussions for sharing more example usages of Whisper and third-party extensions such as web demos, integrations with other tools, ports for different platforms, etc.\n\n\n## License\n\nWhisper's code and model weights are released under the MIT License. See [LICENSE](https://github.com/openai/whisper/blob/main/LICENSE) for further details.","description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/openai/whisper","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"openai-whisper","package_url":"https://pypi.org/project/openai-whisper/","platform":null,"project_url":"https://pypi.org/project/openai-whisper/","project_urls":{"Homepage":"https://github.com/openai/whisper"},"provides_extra":null,"release_url":"https://pypi.org/project/openai-whisper/20231117/","requires_dist":null,"requires_python":">=3.8","summary":"Robust Speech Recognition via Large-Scale Weak Supervision","version":"20231117","yanked":false,"yanked_reason":null},"last_serial":20685157,"releases":{"20230117":[{"comment_text":"","digests":{"blake2b_256":"eab5321fed5de3e0bf435f60e69be7871cb6544613fab2f720f92673edff6be2","md5":"a1f6963e87941acbcedd55ef3626b4a4","sha256":"54d835d80d253363bb942225a94233ef1ca4029c6cc878dc4ce86fa422ba32e7"},"downloads":-1,"filename":"openai-whisper-20230117.tar.gz","has_sig":false,"md5_digest":"a1f6963e87941acbcedd55ef3626b4a4","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":1163998,"upload_time":"2023-01-18T00:13:10","upload_time_iso_8601":"2023-01-18T00:13:10.812200Z","url":"https://files.pythonhosted.org/packages/ea/b5/321fed5de3e0bf435f60e69be7871cb6544613fab2f720f92673edff6be2/openai-whisper-20230117.tar.gz","yanked":false,"yanked_reason":null}],"20230124":[{"comment_text":"","digests":{"blake2b_256":"00c6fb251c4f7de1c78753a2d54d6aaf1a859ddc3797ed4d6003f15866f4c4a4","md5":"7f5373d41aa952d8b1c02335fbc80da8","sha256":"31adf9353bf0e3f891b6618896f22c65cf78cd6f845a4d5b7125aa5102187f79"},"downloads":-1,"filename":"openai-whisper-20230124.tar.gz","has_sig":false,"md5_digest":"7f5373d41aa952d8b1c02335fbc80da8","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":1164776,"upload_time":"2023-01-24T19:12:03","upload_time_iso_8601":"2023-01-24T19:12:03.088960Z","url":"https://files.pythonhosted.org/packages/00/c6/fb251c4f7de1c78753a2d54d6aaf1a859ddc3797ed4d6003f15866f4c4a4/openai-whisper-20230124.tar.gz","yanked":false,"yanked_reason":null}],"20230306":[{"comment_text":"","digests":{"blake2b_256":"deccc4f545ee0b1c97a972e93ac45dc3abdb36b196e689426ee6cd28833dfa80","md5":"5c6b2dd9f52e70c8fb81a0e63394ba92","sha256":"3c7719d6a10c7842e870a9da5fa9df474d8260d0058dfb8cc81f2ef323880e64"},"downloads":-1,"filename":"openai-whisper-20230306.tar.gz","has_sig":false,"md5_digest":"5c6b2dd9f52e70c8fb81a0e63394ba92","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":1172213,"upload_time":"2023-03-07T02:53:49","upload_time_iso_8601":"2023-03-07T02:53:49.169387Z","url":"https://files.pythonhosted.org/packages/de/cc/c4f545ee0b1c97a972e93ac45dc3abdb36b196e689426ee6cd28833dfa80/openai-whisper-20230306.tar.gz","yanked":false,"yanked_reason":null}],"20230307":[{"comment_text":"","digests":{"blake2b_256":"3a25ad2073687b305e663cd1bd1cfdc6070b5399a2eef27cdb3d4b93a3aad88d","md5":"e4a417f9bab798f4a72231cd468674e3","sha256":"0eb705930f67e3b83a8bf57e421572e3fc3686f9197df5ae33efb45fd0ef8fd8"},"downloads":-1,"filename":"openai-whisper-20230307.tar.gz","has_sig":false,"md5_digest":"e4a417f9bab798f4a72231cd468674e3","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":1172195,"upload_time":"2023-03-08T04:37:10","upload_time_iso_8601":"2023-03-08T04:37:10.730315Z","url":"https://files.pythonhosted.org/packages/3a/25/ad2073687b305e663cd1bd1cfdc6070b5399a2eef27cdb3d4b93a3aad88d/openai-whisper-20230307.tar.gz","yanked":false,"yanked_reason":null}],"20230308":[{"comment_text":"","digests":{"blake2b_256":"7723e10f6a5ecd0b883eeaa4f9481ffa374502a0eef333b6d3c98cab15096f0e","md5":"d861857fa7b5fba355dd004b0f09246a","sha256":"bb75d41b3b6b56de984b475833a7eb5e35374b5cae1362b0ed3a414c8ca7d596"},"downloads":-1,"filename":"openai-whisper-20230308.tar.gz","has_sig":false,"md5_digest":"d861857fa7b5fba355dd004b0f09246a","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":1172214,"upload_time":"2023-03-08T23:49:57","upload_time_iso_8601":"2023-03-08T23:49:57.989563Z","url":"https://files.pythonhosted.org/packages/77/23/e10f6a5ecd0b883eeaa4f9481ffa374502a0eef333b6d3c98cab15096f0e/openai-whisper-20230308.tar.gz","yanked":false,"yanked_reason":null}],"20230314":[{"comment_text":"","digests":{"blake2b_256":"808b13b7bf32b83fce396a814678661afdb8839b6b4713b3f2f2bc1499888654","md5":"b9dc1c05d2310b0605c58fa4143ff260","sha256":"7a8e62334f97a8d143b439ae8ed6638d78f41ad921a0205382354004b7271725"},"downloads":-1,"filename":"openai-whisper-20230314.tar.gz","has_sig":false,"md5_digest":"b9dc1c05d2310b0605c58fa4143ff260","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":792929,"upload_time":"2023-03-15T07:40:05","upload_time_iso_8601":"2023-03-15T07:40:05.746043Z","url":"https://files.pythonhosted.org/packages/80/8b/13b7bf32b83fce396a814678661afdb8839b6b4713b3f2f2bc1499888654/openai-whisper-20230314.tar.gz","yanked":false,"yanked_reason":null}],"20230918":[{"comment_text":"","digests":{"blake2b_256":"78ef74ad84ad319fb9be8798ecccdd6384d346b63b54dffb8478234c43f778a1","md5":"af1733d2fcff30a78966779d288e0f75","sha256":"32a1ee39c3faaf6c719e3a83f1aacc8e164aad87976350371e26845271287c30"},"downloads":-1,"filename":"openai-whisper-20230918.tar.gz","has_sig":false,"md5_digest":"af1733d2fcff30a78966779d288e0f75","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":794348,"upload_time":"2023-09-19T00:13:46","upload_time_iso_8601":"2023-09-19T00:13:46.496013Z","url":"https://files.pythonhosted.org/packages/78/ef/74ad84ad319fb9be8798ecccdd6384d346b63b54dffb8478234c43f778a1/openai-whisper-20230918.tar.gz","yanked":false,"yanked_reason":null}],"20231105":[{"comment_text":"","digests":{"blake2b_256":"90cbcb99e1d5bccb9c85155c61e647050939780acabdf3f92275ac59737c2174","md5":"191e7556c96381808f057b48d734b268","sha256":"b04b60526d372e3c537f7cfe3735765e0478c3cd8b7e0922ba98768b1ff4fca5"},"downloads":-1,"filename":"openai-whisper-20231105.tar.gz","has_sig":false,"md5_digest":"191e7556c96381808f057b48d734b268","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":794848,"upload_time":"2023-11-06T11:09:30","upload_time_iso_8601":"2023-11-06T11:09:30.603356Z","url":"https://files.pythonhosted.org/packages/90/cb/cb99e1d5bccb9c85155c61e647050939780acabdf3f92275ac59737c2174/openai-whisper-20231105.tar.gz","yanked":false,"yanked_reason":null}],"20231106":[{"comment_text":"","digests":{"blake2b_256":"6346b5f9d697b138ef9885dd3e8a08c6475c1cbd747f2dfc14a437fe3b02b58e","md5":"07076346da647af9b74329d18753230e","sha256":"9d1de7fa1e766b9adf8be4bfa7fb11e2bdf8d2b0bf77b90478cf4d75e0e58d19"},"downloads":-1,"filename":"openai-whisper-20231106.tar.gz","has_sig":false,"md5_digest":"07076346da647af9b74329d18753230e","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":798577,"upload_time":"2023-11-06T18:16:21","upload_time_iso_8601":"2023-11-06T18:16:21.951232Z","url":"https://files.pythonhosted.org/packages/63/46/b5f9d697b138ef9885dd3e8a08c6475c1cbd747f2dfc14a437fe3b02b58e/openai-whisper-20231106.tar.gz","yanked":false,"yanked_reason":null}],"20231117":[{"comment_text":"","digests":{"blake2b_256":"d26e50ace2bf704e5ffc786d20d96403ab0d57c5d6ab8729de7fed8c436687df","md5":"9df9549bc62ad7b4f9fd7c8e6eadf81d","sha256":"7af424181436f1800cc0b7d75cf40ede34e9ddf1ba4983a910832fcf4aade4a4"},"downloads":-1,"filename":"openai-whisper-20231117.tar.gz","has_sig":false,"md5_digest":"9df9549bc62ad7b4f9fd7c8e6eadf81d","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":798593,"upload_time":"2023-11-17T19:59:56","upload_time_iso_8601":"2023-11-17T19:59:56.498672Z","url":"https://files.pythonhosted.org/packages/d2/6e/50ace2bf704e5ffc786d20d96403ab0d57c5d6ab8729de7fed8c436687df/openai-whisper-20231117.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"d26e50ace2bf704e5ffc786d20d96403ab0d57c5d6ab8729de7fed8c436687df","md5":"9df9549bc62ad7b4f9fd7c8e6eadf81d","sha256":"7af424181436f1800cc0b7d75cf40ede34e9ddf1ba4983a910832fcf4aade4a4"},"downloads":-1,"filename":"openai-whisper-20231117.tar.gz","has_sig":false,"md5_digest":"9df9549bc62ad7b4f9fd7c8e6eadf81d","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":798593,"upload_time":"2023-11-17T19:59:56","upload_time_iso_8601":"2023-11-17T19:59:56.498672Z","url":"https://files.pythonhosted.org/packages/d2/6e/50ace2bf704e5ffc786d20d96403ab0d57c5d6ab8729de7fed8c436687df/openai-whisper-20231117.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
