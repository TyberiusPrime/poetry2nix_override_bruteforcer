{"info":{"author":"Sasha Rush","author_email":"srush.research@gmail.com","bugtrack_url":null,"classifiers":["Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering"],"description":"<img src=\"https://user-images.githubusercontent.com/35882/227030644-f70e55e8-68a3-48d3-afa3-54c4de8fc210.png\" width=\"100%\">\n\nA tiny library for coding with **large** language models. Check out the [MiniChain Zoo](https://srush-minichain.hf.space/) to get a sense of how it works.\n\n## Coding\n\n* Code ([math_demo.py](https://github.com/srush/MiniChain/blob/main/examples/math_demo.py)): Annotate Python functions that call language models.\n\n```python\n@prompt(OpenAI(), template_file=\"math.pmpt.tpl\"\ndef math_prompt(model, question):\n    \"Prompt to call GPT with a Jinja template\"\n    return model(dict(question=question))\n\n@prompt(Python(), template=\"import math\\n{{code}}\")\ndef python(model, code):\n    \"Prompt to call Python interpreter\"\n    code = \"\\n\".join(code.strip().split(\"\\n\")[1:-1])\n    return model(dict(code=code))\n\ndef math_demo(question):\n    \"Chain them together\"\n    return python(math_prompt(question))\n```\n\n* Chains ([Space](https://srush-minichain.hf.space/)): MiniChain builds a graph (think like PyTorch) of all the calls you make for debugging and error handling.\n<img src=\"https://user-images.githubusercontent.com/35882/226965531-78df7927-988d-45a7-9faa-077359876730.png\" width=\"50%\">\n\n\n```python\nshow(math_demo,\n     examples=[\"What is the sum of the powers of 3 (3^i) that are smaller than 100?\",\n               \"What is the sum of the 10 first positive integers?\"],\n     subprompts=[math_prompt, python],\n     out_type=\"markdown\").queue().launch()\n```\n\n\n* Template ([math.pmpt.tpl](https://github.com/srush/MiniChain/blob/main/examples/math.pmpt.tpl)): Prompts are separated from code.\n\n```\n...\nQuestion:\nA robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts in total does it take?\nCode:\n2 + 2/2\n\nQuestion:\n{{question}}\nCode:\n```\n\n* Installation\n\n```bash\npip install minichain\nexport OPENAI_API_KEY=\"sk-***\"\n```\n\n## Examples\n\nThis library allows us to implement several popular approaches in a few lines of code.\n\n* [Retrieval-Augmented QA](https://srush.github.io/MiniChain/examples/qa/)\n* [Chat with memory](https://srush.github.io/MiniChain/examples/chatgpt/)\n* [Information Extraction](https://srush.github.io/MiniChain/examples/ner/)\n* [Interleaved Code (PAL)](https://srush.github.io/MiniChain/examples/pal/) - [(Gao et al 2022)](https://arxiv.org/pdf/2211.10435.pdf)\n* [Search Augmentation (Self-Ask)](https://srush.github.io/MiniChain/examples/selfask/) - [(Press et al 2022)](https://ofir.io/self-ask.pdf)\n* [Chain-of-Thought](https://srush.github.io/MiniChain/examples/bash/) - [(Wei et al 2022)](https://arxiv.org/abs/2201.11903)\n\nIt supports the current backends.\n\n* OpenAI (Completions / Embeddings)\n* Hugging Face 🤗\n* Google Search\n* Python\n* Manifest-ML (AI21, Cohere, Together)\n* Bash\n\n## Why Mini-Chain?\n\nThere are several very popular libraries for prompt chaining,\nnotably: [LangChain](https://langchain.readthedocs.io/en/latest/),\n[Promptify](https://github.com/promptslab/Promptify), and\n[GPTIndex](https://gpt-index.readthedocs.io/en/latest/reference/prompts.html).\nThese library are useful, but they are extremely large and\ncomplex. MiniChain aims to implement the core prompt chaining\nfunctionality in a tiny digestable library.\n\n\n## Tutorial\n\nMini-chain is based on annotating functions as prompts.\n\n![image](https://user-images.githubusercontent.com/35882/221280012-d58c186d-4da2-4cb6-96af-4c4d9069943f.png)\n\n\n```python\n@prompt(OpenAI())\ndef color_prompt(model, input):\n    return model(f\"Answer 'Yes' if this is a color, {input}. Answer:\")\n```\n\nPrompt functions act like python functions, except they are lazy to access the result you need to call `run()`.\n\n```python\nif color_prompt(\"blue\").run() == \"Yes\":\n    print(\"It's a color\")\n```\nAlternatively you can chain prompts together. Prompts are lazy, so if you want to manipulate them you need to add `@transform()` to your function. For example:\n\n```python\n@transform()\ndef said_yes(input):\n    return input == \"Yes\"\n```\n\n![image](https://user-images.githubusercontent.com/35882/221281771-3770be96-02ce-4866-a6f8-c458c9a11c6f.png)\n\n```python\n@prompt(OpenAI())\ndef adjective_prompt(model, input):\n    return model(f\"Give an adjective to describe {input}. Answer:\")\n```\n\n\n```python\nadjective = adjective_prompt(\"rainbow\")\nif said_yes(color_prompt(adjective)).run():\n    print(\"It's a color\")\n```\n\n\nWe also include an argument `template_file` which assumes model uses template from the\n[Jinja](https://jinja.palletsprojects.com/en/3.1.x/templates/) language.\nThis allows us to separate prompt text from the python code.\n\n```python\n@prompt(OpenAI(), template_file=\"math.pmpt.tpl\")\ndef math_prompt(model, question):\n    return model(dict(question=question))\n```\n\n### Visualization\n\nMiniChain has a built-in prompt visualization system using `Gradio`.\nIf you construct a function that calls a prompt chain you can visualize it\nby calling `show` and `launch`. This can be done directly in a notebook as well.\n\n```python\nshow(math_demo,\n     examples=[\"What is the sum of the powers of 3 (3^i) that are smaller than 100?\",\n              \"What is the sum of the 10 first positive integers?\"],\n     subprompts=[math_prompt, python],\n     out_type=\"markdown\").queue().launch()\n```\n\n\n### Memory\n\nMiniChain does not build in an explicit stateful memory class. We recommend implementing it as a queue.\n\n![image](https://user-images.githubusercontent.com/35882/221622653-7b13783e-0439-4d59-8f57-b98b82ab83c0.png)\n\nHere is a class you might find useful to keep track of responses.\n\n```python\n@dataclass\nclass State:\n    memory: List[Tuple[str, str]]\n    human_input: str = \"\"\n\n    def push(self, response: str) -> \"State\":\n        memory = self.memory if len(self.memory) < MEMORY_LIMIT else self.memory[1:]\n        return State(memory + [(self.human_input, response)])\n```\n\nSee the full Chat example.\nIt keeps track of the last two responses that it has seen.\n\n### Tools and agents.\n\nMiniChain does not provide `agents` or `tools`. If you want that functionality you can use the `tool_num` argument of model which allows you to select from multiple different possible backends. It's easy to add new backends of your own (see the GradioExample).\n\n```python\n@prompt([Python(), Bash()])\ndef math_prompt(model, input, lang):\n    return model(input, tool_num= 0 if lang == \"python\" else 1)\n```\n\n### Documents and Embeddings\n\nMiniChain does not manage documents and embeddings. We recommend using\nthe [Hugging Face Datasets](https://huggingface.co/docs/datasets/index) library with\nbuilt in FAISS indexing.\n\n![image](https://user-images.githubusercontent.com/35882/221387303-e3dd8456-a0f0-4a70-a1bb-657fe2240862.png)\n\n\nHere is the implementation.\n\n```python\n# Load and index a dataset\nolympics = datasets.load_from_disk(\"olympics.data\")\nolympics.add_faiss_index(\"embeddings\")\n\n@prompt(OpenAIEmbed())\ndef get_neighbors(model, inp, k):\n    embedding = model(inp)\n    res = olympics.get_nearest_examples(\"embeddings\", np.array(embedding), k)\n    return res.examples[\"content\"]\n```\n\nThis creates a K-nearest neighbors (KNN) prompt that looks up the\n3 closest documents based on embeddings of the question asked.\nSee the full [Retrieval-Augemented QA](https://srush.github.io/MiniChain/examples/qa/)\nexample.\n\n\nWe recommend creating these embeddings offline using the batch map functionality of the\ndatasets library.\n\n```python\ndef embed(x):\n    emb = openai.Embedding.create(input=x[\"content\"], engine=EMBEDDING_MODEL)\n    return {\"embeddings\": [np.array(emb['data'][i]['embedding'])\n                           for i in range(len(emb[\"data\"]))]}\nx = dataset.map(embed, batch_size=BATCH_SIZE, batched=True)\nx.save_to_disk(\"olympics.data\")\n```\n\nThere are other ways to do this such as [sqllite](https://github.com/asg017/sqlite-vss)\nor [Weaviate](https://weaviate.io/).\n\n\n### Typed Prompts\n\nMiniChain can automatically generate a prompt header for you that aims to ensure the\noutput follows a given typed specification. For example, if you run the following code\nMiniChain will produce prompt that returns a list of `Player` objects.\n\n```python\nclass StatType(Enum):\n    POINTS = 1\n    REBOUNDS = 2\n    ASSISTS = 3\n\n@dataclass\nclass Stat:\n    value: int\n    stat: StatType\n\n@dataclass\nclass Player:\n    player: str\n    stats: List[Stat]\n\n\n@prompt(OpenAI(), template_file=\"stats.pmpt.tpl\", parser=\"json\")\ndef stats(model, passage):\n    out = model(dict(passage=passage, typ=type_to_prompt(Player)))\n    return [Player(**j) for j in out]\n```\n\nSpecifically it will provide your template with a string `typ` that you can use. For this example the string will be of the following form:\n\n\n```\nYou are a highly intelligent and accurate information extraction system. You take passage as input and your task is to find parts of the passage to answer questions.\n\nYou need to output a list of JSON encoded values\n\nYou need to classify in to the following types for key: \"color\":\n\nRED\nGREEN\nBLUE\n\n\nOnly select from the above list, or \"Other\".⏎\n\n\nYou need to classify in to the following types for key: \"object\":⏎\n\nString\n\n\n\nYou need to classify in to the following types for key: \"explanation\":\n\nString\n\n[{ \"color\" : \"color\" ,  \"object\" : \"object\" ,  \"explanation\" : \"explanation\"}, ...]\n\nMake sure every output is exactly seen in the document. Find as many as you can.\n```\n\nThis will then be converted to an object automatically for you.\n\n\n\n\n","description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/srush/minichain","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"minichain","package_url":"https://pypi.org/project/minichain/","platform":null,"project_url":"https://pypi.org/project/minichain/","project_urls":{"Documentation":"https://srush.github.io/minichain","Homepage":"https://github.com/srush/minichain","Issue Tracker":"https://github.com/srush/minichain/issues","Source Code":"https://github.com/srush/minichain"},"provides_extra":null,"release_url":"https://pypi.org/project/minichain/0.3.3/","requires_dist":null,"requires_python":"","summary":"A tiny library for large language models","version":"0.3.3","yanked":false,"yanked_reason":null},"last_serial":17772775,"releases":{"0.2.2":[{"comment_text":"","digests":{"blake2b_256":"bcd4f8abf794401aa91b59489ef47c1e9a5bc325af2bcbbde24a8ec3a088b256","md5":"d3dbd8c9b3f85a96e078fa8a3da0cddd","sha256":"54b977ae557b168405ba59b81fec02e37f6da3d2bb90a6b94ecc987cdf12941d"},"downloads":-1,"filename":"minichain-0.2.2.tar.gz","has_sig":false,"md5_digest":"d3dbd8c9b3f85a96e078fa8a3da0cddd","packagetype":"sdist","python_version":"source","requires_python":null,"size":19565,"upload_time":"2023-04-13T22:51:01","upload_time_iso_8601":"2023-04-13T22:51:01.089424Z","url":"https://files.pythonhosted.org/packages/bc/d4/f8abf794401aa91b59489ef47c1e9a5bc325af2bcbbde24a8ec3a088b256/minichain-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"0.2.3":[{"comment_text":"","digests":{"blake2b_256":"03ce513f2fd763e5e6af6397a69fde41f2a195c13a136582275be3e34497c8bb","md5":"c4300c1d4d82dfd257268a29ffef1000","sha256":"e587b3f8ad6ef921db9a6975651e7fdb501efdd103b31b0e5dd3508baa2769e5"},"downloads":-1,"filename":"minichain-0.2.3.linux-x86_64.tar.gz","has_sig":false,"md5_digest":"c4300c1d4d82dfd257268a29ffef1000","packagetype":"sdist","python_version":"source","requires_python":null,"size":33184,"upload_time":"2023-04-13T22:54:30","upload_time_iso_8601":"2023-04-13T22:54:30.260504Z","url":"https://files.pythonhosted.org/packages/03/ce/513f2fd763e5e6af6397a69fde41f2a195c13a136582275be3e34497c8bb/minichain-0.2.3.linux-x86_64.tar.gz","yanked":false,"yanked_reason":null}],"0.3":[{"comment_text":"","digests":{"blake2b_256":"88337cb885ae280bf0c53a66c88332c211e1cbe594a5811b58d2501e0d307b12","md5":"07b23e48ccfaaabbb9ee68169454b5a8","sha256":"87bd894b760efcbe7f74786c95fe69adbe9db2e69f5662e214d30401265df1ab"},"downloads":-1,"filename":"minichain-0.3.linux-x86_64.tar.gz","has_sig":false,"md5_digest":"07b23e48ccfaaabbb9ee68169454b5a8","packagetype":"sdist","python_version":"source","requires_python":null,"size":33718,"upload_time":"2023-04-18T20:10:51","upload_time_iso_8601":"2023-04-18T20:10:51.460284Z","url":"https://files.pythonhosted.org/packages/88/33/7cb885ae280bf0c53a66c88332c211e1cbe594a5811b58d2501e0d307b12/minichain-0.3.linux-x86_64.tar.gz","yanked":false,"yanked_reason":null}],"0.3.1":[{"comment_text":"","digests":{"blake2b_256":"6b2771a9906ce5055175ac1de010757deaccf9209911d7f8dc6cb1654455675e","md5":"ff0ab92a2d577626a4df821a716d12fc","sha256":"55294ca8919dd9a990ffb10ae6d6607a9bc6000df9f4c5f93d0910de93cc9185"},"downloads":-1,"filename":"minichain-0.3.1.linux-x86_64.tar.gz","has_sig":false,"md5_digest":"ff0ab92a2d577626a4df821a716d12fc","packagetype":"sdist","python_version":"source","requires_python":null,"size":33778,"upload_time":"2023-04-18T22:17:17","upload_time_iso_8601":"2023-04-18T22:17:17.254594Z","url":"https://files.pythonhosted.org/packages/6b/27/71a9906ce5055175ac1de010757deaccf9209911d7f8dc6cb1654455675e/minichain-0.3.1.linux-x86_64.tar.gz","yanked":false,"yanked_reason":null}],"0.3.2":[{"comment_text":"","digests":{"blake2b_256":"be2ef3d4fbce9386e5d3e607883c1964c161ba0c9f7e3ce2bdca88b068f3ac56","md5":"9d5e44876f30ee5b38a25c471d171501","sha256":"164488a0e20ef541232a547808be81c9090b11e5047472cf09cf16e41c4216a7"},"downloads":-1,"filename":"minichain-0.3.2.linux-x86_64.tar.gz","has_sig":false,"md5_digest":"9d5e44876f30ee5b38a25c471d171501","packagetype":"sdist","python_version":"source","requires_python":null,"size":31756,"upload_time":"2023-04-19T15:10:37","upload_time_iso_8601":"2023-04-19T15:10:37.541427Z","url":"https://files.pythonhosted.org/packages/be/2e/f3d4fbce9386e5d3e607883c1964c161ba0c9f7e3ce2bdca88b068f3ac56/minichain-0.3.2.linux-x86_64.tar.gz","yanked":false,"yanked_reason":null}],"0.3.3":[{"comment_text":"","digests":{"blake2b_256":"fa39f665cbbeae6a22c43859807c76dbddd253dc7071439483bf2accfe89c1e9","md5":"b947ccc2ecd1c4f4570204977a1e6111","sha256":"fa68eed4ccff6a88d13a988e573bfa5a844d4eb8600ae6f8cb260b1167075a1d"},"downloads":-1,"filename":"minichain-0.3.3.tar.gz","has_sig":false,"md5_digest":"b947ccc2ecd1c4f4570204977a1e6111","packagetype":"sdist","python_version":"source","requires_python":null,"size":20438,"upload_time":"2023-04-19T15:18:27","upload_time_iso_8601":"2023-04-19T15:18:27.903343Z","url":"https://files.pythonhosted.org/packages/fa/39/f665cbbeae6a22c43859807c76dbddd253dc7071439483bf2accfe89c1e9/minichain-0.3.3.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"fa39f665cbbeae6a22c43859807c76dbddd253dc7071439483bf2accfe89c1e9","md5":"b947ccc2ecd1c4f4570204977a1e6111","sha256":"fa68eed4ccff6a88d13a988e573bfa5a844d4eb8600ae6f8cb260b1167075a1d"},"downloads":-1,"filename":"minichain-0.3.3.tar.gz","has_sig":false,"md5_digest":"b947ccc2ecd1c4f4570204977a1e6111","packagetype":"sdist","python_version":"source","requires_python":null,"size":20438,"upload_time":"2023-04-19T15:18:27","upload_time_iso_8601":"2023-04-19T15:18:27.903343Z","url":"https://files.pythonhosted.org/packages/fa/39/f665cbbeae6a22c43859807c76dbddd253dc7071439483bf2accfe89c1e9/minichain-0.3.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
