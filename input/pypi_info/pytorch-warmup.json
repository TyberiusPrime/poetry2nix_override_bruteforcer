{"info":{"author":"Takenori Yamamoto","author_email":"yamamoto.takenory@gmail.com","bugtrack_url":null,"classifiers":["Intended Audience :: Science/Research","License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Software Development :: Libraries :: Python Modules"],"description":"# A PyTorch Extension for Learning Rate Warmup\n\nThis library contains PyTorch implementations of the warmup schedules described in [On the adequacy of untuned warmup for adaptive optimization](https://arxiv.org/abs/1910.04209).\n\n<p align=\"center\"><img src=\"https://github.com/Tony-Y/pytorch_warmup/raw/master/examples/plots/figs/warmup_schedule.png\" alt=\"Warmup schedule\" width=\"400\"/></p>\n\n![Python package](https://github.com/Tony-Y/pytorch_warmup/workflows/Python%20package/badge.svg)\n[![PyPI version shields.io](https://img.shields.io/pypi/v/pytorch-warmup.svg)](https://pypi.python.org/pypi/pytorch-warmup/)\n[![PyPI license](https://img.shields.io/pypi/l/pytorch-warmup.svg)](https://pypi.python.org/pypi/pytorch-warmup/)\n[![PyPI pyversions](https://img.shields.io/pypi/pyversions/pytorch-warmup.svg)](https://pypi.python.org/pypi/pytorch-warmup/)\n\n## Installation\n\nMake sure you have Python 3.6+ and PyTorch 1.1+. Then, run the following command:\n\n```\npython setup.py install\n```\n\nor\n\n```\npip install -U pytorch_warmup\n```\n\n## Usage\n\n### Sample Codes\n\nThe scheduled learning rate is dampened by the multiplication of the warmup factor:\n\n<p align=\"center\"><img src=\"https://github.com/Tony-Y/pytorch_warmup/raw/master/examples/emnist/figs/learning_rate.png\" alt=\"Learning rate\" width=\"400\"/></p>\n\n#### Approach 1\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tony-Y/colab-notebooks/blob/master/PyTorch_Warmup_Approach1_chaining.ipynb)\n\nWhen the learning rate schedule uses the global iteration number, the untuned linear warmup can be used as follows:\n\n```python\nimport torch\nimport pytorch_warmup as warmup\n\noptimizer = torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), weight_decay=0.01)\nnum_steps = len(dataloader) * num_epochs\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\nwarmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\nfor epoch in range(1,num_epochs+1):\n    for batch in dataloader:\n        optimizer.zero_grad()\n        loss = ...\n        loss.backward()\n        optimizer.step()\n        with warmup_scheduler.dampening():\n            lr_scheduler.step()\n```\n\nIf you want to use the learning rate schedule \"chaining\" which is supported for PyTorch 1.4.0 or above, you may simply give a code of learning rate schedulers as a suite of the `with` statement:\n```python\nlr_scheduler1 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\nlr_scheduler2 = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\nwarmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\nfor epoch in range(1,num_epochs+1):\n    for batch in dataloader:\n        ...\n        optimizer.step()\n        with warmup_scheduler.dampening():\n            lr_scheduler1.step()\n            lr_scheduler2.step()\n```\n\n#### Approach 2\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tony-Y/colab-notebooks/blob/master/PyTorch_Warmup_Approach2_chaining.ipynb)\n\nWhen the learning rate schedule uses the epoch number, the warmup schedule can be used as follows:\n\n```python\nlr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[num_epochs//3], gamma=0.1)\nwarmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\nfor epoch in range(1,num_epochs+1):\n    for iter, batch in enumerate(dataloader):\n        optimizer.zero_grad()\n        loss = ...\n        loss.backward()\n        optimizer.step()\n        if iter < len(dataloader)-1:\n            with warmup_scheduler.dampening():\n                pass\n    with warmup_scheduler.dampening():\n        lr_scheduler.step()\n```\n\n### Warmup Schedules\n\n#### Manual Warmup\n\nThe warmup factor `w(t)` depends on the warmup period, which must manually be specified, for `LinearWarmup` and `ExponentialWarmup`.\n\n##### Linear\n\n`w(t) = min(1, t / warmup_period)`\n\n```python\nwarmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=2000)\n```\n\n##### Exponential\n\n`w(t) = 1 - exp(-t / warmup_period)`\n\n```python\nwarmup_scheduler = warmup.ExponentialWarmup(optimizer, warmup_period=1000)\n```\n\n#### Untuned Warmup\n\nThe warmup period is given by a function of Adam's `beta2` parameter for `UntunedLinearWarmup` and `UntunedExponentialWarmup`.\n\n##### Linear\n\n`warmup_period = 2 / (1 - beta2)`\n\n```python\nwarmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\n```\n\n##### Exponential\n\n`warmup_period = 1 / (1 - beta2)`\n\n```python\nwarmup_scheduler = warmup.UntunedExponentialWarmup(optimizer)\n```\n\n#### RAdam Warmup\n\nThe warmup factor depends on Adam's `beta2` parameter for `RAdamWarmup`. Please see the original paper for the details.\n\n```python\nwarmup_scheduler = warmup.RAdamWarmup(optimizer)\n```\n\n### Apex's Adam\n\nThe Apex library provides an Adam optimizer tuned for CUDA devices, [FusedAdam](https://nvidia.github.io/apex/optimizers.html#apex.optimizers.FusedAdam). The FusedAdam optimizer can be used with the warmup schedulers. For example:\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tony-Y/colab-notebooks/blob/master/PyTorch_Warmup_FusedAdam.ipynb)\n\n```python\noptimizer = apex.optimizers.FusedAdam(params, lr=0.001, betas=(0.9, 0.999), weight_decay=0.01)\nlr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_steps)\nwarmup_scheduler = warmup.UntunedLinearWarmup(optimizer)\n```\n\n\n## License\n\nMIT License\n\nCopyright (c) 2019 Takenori Yamamoto\n","description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/Tony-Y/pytorch_warmup","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"pytorch-warmup","package_url":"https://pypi.org/project/pytorch-warmup/","platform":null,"project_url":"https://pypi.org/project/pytorch-warmup/","project_urls":{"Homepage":"https://github.com/Tony-Y/pytorch_warmup"},"provides_extra":null,"release_url":"https://pypi.org/project/pytorch-warmup/0.1.1/","requires_dist":["torch (>=1.1)"],"requires_python":">=3.7","summary":"A PyTorch Extension for Learning Rate Warmup","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":15506234,"releases":{"0.0.3":[{"comment_text":"","digests":{"blake2b_256":"398a792ddf9bb209c71dc7ea753d3a2990d924a6c07eb2cc30de4cfacf8d3645","md5":"4873556236e2195b56a25d91ec16144d","sha256":"d10c8704b1e2adf3efa84480cc15572b70b05117b2417d4a8897524c011f4d28"},"downloads":-1,"filename":"pytorch_warmup-0.0.3-py3-none-any.whl","has_sig":false,"md5_digest":"4873556236e2195b56a25d91ec16144d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":4952,"upload_time":"2019-10-31T11:48:28","upload_time_iso_8601":"2019-10-31T11:48:28.824167Z","url":"https://files.pythonhosted.org/packages/39/8a/792ddf9bb209c71dc7ea753d3a2990d924a6c07eb2cc30de4cfacf8d3645/pytorch_warmup-0.0.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8cba995c87140dc058ca664fa36df875c3596364c31b84193ffe7011089cef26","md5":"b1cbd80e5a5e1d85de3c95da2477ee4f","sha256":"64c992276d454d8267bdfdf5060028c8aae121df4f45ed7241653c78e0aadc4f"},"downloads":-1,"filename":"pytorch-warmup-0.0.3.tar.gz","has_sig":false,"md5_digest":"b1cbd80e5a5e1d85de3c95da2477ee4f","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":310448,"upload_time":"2019-10-31T11:48:32","upload_time_iso_8601":"2019-10-31T11:48:32.807322Z","url":"https://files.pythonhosted.org/packages/8c/ba/995c87140dc058ca664fa36df875c3596364c31b84193ffe7011089cef26/pytorch-warmup-0.0.3.tar.gz","yanked":false,"yanked_reason":null}],"0.0.4":[{"comment_text":"","digests":{"blake2b_256":"7a222fb600a06a1d1b493d54ac8fa6c41e96870985992fc504104e0620bc2ea4","md5":"7912af946575fdcf191ce1de924af2d8","sha256":"38110440a51840120732844e1e312227bb787a2e675589c241484b95a6d515bc"},"downloads":-1,"filename":"pytorch_warmup-0.0.4-py3-none-any.whl","has_sig":false,"md5_digest":"7912af946575fdcf191ce1de924af2d8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":6478,"upload_time":"2019-11-14T08:51:10","upload_time_iso_8601":"2019-11-14T08:51:10.763884Z","url":"https://files.pythonhosted.org/packages/7a/22/2fb600a06a1d1b493d54ac8fa6c41e96870985992fc504104e0620bc2ea4/pytorch_warmup-0.0.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"da323a662cf200368441d4f8c34b6da4c2037fa767a5c6ab9a19b136899482a5","md5":"fa618189316894e7d780f028621b9bbb","sha256":"9c630ac77a76f594492ffad8ccd5015aa5c946aee71525f867a86c88aaacd922"},"downloads":-1,"filename":"pytorch-warmup-0.0.4.tar.gz","has_sig":false,"md5_digest":"fa618189316894e7d780f028621b9bbb","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":312831,"upload_time":"2019-11-14T08:51:14","upload_time_iso_8601":"2019-11-14T08:51:14.250736Z","url":"https://files.pythonhosted.org/packages/da/32/3a662cf200368441d4f8c34b6da4c2037fa767a5c6ab9a19b136899482a5/pytorch-warmup-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"0.1.0":[{"comment_text":"","digests":{"blake2b_256":"1995a9fb4ddf493a3df4a0ca947cc03ab452c569e5c5d5c66e31bfbdcfd2ae99","md5":"fd109652b4f9c6bc16092f55090351f4","sha256":"6462c34b6942a61df54bca72c3ed7c8df8ef7089ade1f39724ec15e47022fb45"},"downloads":-1,"filename":"pytorch-warmup-0.1.0.tar.gz","has_sig":false,"md5_digest":"fd109652b4f9c6bc16092f55090351f4","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":314318,"upload_time":"2022-04-07T12:49:10","upload_time_iso_8601":"2022-04-07T12:49:10.406185Z","url":"https://files.pythonhosted.org/packages/19/95/a9fb4ddf493a3df4a0ca947cc03ab452c569e5c5d5c66e31bfbdcfd2ae99/pytorch-warmup-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"0.1.1":[{"comment_text":"","digests":{"blake2b_256":"b989adb6809ac3d587a725ff1d0cd79e0a75bc3a20c3fa1476a917026838f1d0","md5":"e725e1b040a0007d7f37edcf2319dcfc","sha256":"eecc4af0975bb181198c0817be145bccb17c7ea09ce3fdf69140f65d8c32b746"},"downloads":-1,"filename":"pytorch_warmup-0.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"e725e1b040a0007d7f37edcf2319dcfc","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":6625,"upload_time":"2022-10-24T07:16:08","upload_time_iso_8601":"2022-10-24T07:16:08.471932Z","url":"https://files.pythonhosted.org/packages/b9/89/adb6809ac3d587a725ff1d0cd79e0a75bc3a20c3fa1476a917026838f1d0/pytorch_warmup-0.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c102a83b1b0379880621c794d043665c927e9a87764d35d2d8b0a4831e68d8c5","md5":"9e558b9ce50f617f2a93af1b09b7e2af","sha256":"c594760b29657a127aa6a8c3424dd0b5068140b3b7d4988118f4a9f3e99b1457"},"downloads":-1,"filename":"pytorch-warmup-0.1.1.tar.gz","has_sig":false,"md5_digest":"9e558b9ce50f617f2a93af1b09b7e2af","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":313712,"upload_time":"2022-10-24T07:16:10","upload_time_iso_8601":"2022-10-24T07:16:10.801943Z","url":"https://files.pythonhosted.org/packages/c1/02/a83b1b0379880621c794d043665c927e9a87764d35d2d8b0a4831e68d8c5/pytorch-warmup-0.1.1.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"b989adb6809ac3d587a725ff1d0cd79e0a75bc3a20c3fa1476a917026838f1d0","md5":"e725e1b040a0007d7f37edcf2319dcfc","sha256":"eecc4af0975bb181198c0817be145bccb17c7ea09ce3fdf69140f65d8c32b746"},"downloads":-1,"filename":"pytorch_warmup-0.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"e725e1b040a0007d7f37edcf2319dcfc","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":6625,"upload_time":"2022-10-24T07:16:08","upload_time_iso_8601":"2022-10-24T07:16:08.471932Z","url":"https://files.pythonhosted.org/packages/b9/89/adb6809ac3d587a725ff1d0cd79e0a75bc3a20c3fa1476a917026838f1d0/pytorch_warmup-0.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c102a83b1b0379880621c794d043665c927e9a87764d35d2d8b0a4831e68d8c5","md5":"9e558b9ce50f617f2a93af1b09b7e2af","sha256":"c594760b29657a127aa6a8c3424dd0b5068140b3b7d4988118f4a9f3e99b1457"},"downloads":-1,"filename":"pytorch-warmup-0.1.1.tar.gz","has_sig":false,"md5_digest":"9e558b9ce50f617f2a93af1b09b7e2af","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":313712,"upload_time":"2022-10-24T07:16:10","upload_time_iso_8601":"2022-10-24T07:16:10.801943Z","url":"https://files.pythonhosted.org/packages/c1/02/a83b1b0379880621c794d043665c927e9a87764d35d2d8b0a4831e68d8c5/pytorch-warmup-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
