{"info":{"author":"Michael Hansen","author_email":"mike@rhasspy.org","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8"],"description":"# Rhasspy Natural Language Understanding\n\n[![Continuous Integration](https://github.com/rhasspy/rhasspy-nlu/workflows/Tests/badge.svg)](https://github.com/rhasspy/rhasspy-nlu/actions)\n[![PyPI package version](https://img.shields.io/pypi/v/rhasspy-nlu.svg)](https://pypi.org/project/rhasspy-nlu)\n[![Python versions](https://img.shields.io/pypi/pyversions/rhasspy-nlu.svg)](https://www.python.org)\n[![GitHub license](https://img.shields.io/github/license/rhasspy/rhasspy-nlu.svg)](https://github.com/rhasspy/rhasspy-nlu/blob/master/LICENSE)\n\nLibrary for parsing Rhasspy sentence templates, doing intent recognition, and generating ARPA language models.\n\n## Requirements\n\n* Python 3.7\n\n## Installation\n\n```bash\n$ git clone https://github.com/rhasspy/rhasspy-nlu\n$ cd rhasspy-nlu\n$ ./configure\n$ make\n$ make install\n```\n\n## Running\n\n```bash\n$ bin/rhasspy-nlu <ARGS>\n```\n\n## Parsing Sentence Templates\n\nRhasspy voice commands are stored in text files formatted like this:\n\n```ini\n[Intent1]\nthis is a sentence\nthis is another sentence\n\n[Intent2]\na sentence in a different intent\n```\n\nYou can parse these into a structured representation with `rhasspynlu.parse_ini` and then convert them to a graph using `rhasspynlu.intents_to_graph`:\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[LightOn]\nturn on [the] (living room lamp | kitchen light){name}\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(intents)\n```\n\nThe result is a [directed graph](https://networkx.github.io/documentation/networkx-2.3/reference/classes/digraph.html) whose states are words and edges are input/output labels.\n\nYou can pass an `intent_filter` function to `parse_ini` to return `True` for only the intent names you want to parse.\nAdditionally, a function can be provided for the `sentence_transform` argument that each sentence will be passed through (e.g., to lower case).\n\n### Template Syntax\n\nSentence templates are based on the [JSGF](https://www.w3.org/TR/jsgf/) standard. The following constructs are available:\n\n* Optional words\n    * `this is [a] test` - the word \"a\" may or may not be present\n* Alternatives\n    * `set color to (red | green | blue)` - either \"red\", \"green\", or \"blue\" is possible\n* Tags\n    * `turn on the [den | playroom]{location} light` - named entity `location` will be either \"den\" or \"playroom\"\n* Substitutions\n    * `make ten:10 coffees` - output will be \"make 10 coffees\"\n    * `turn off the: (television | tele):tv` - output will be \"turn off tv\"\n    * `set brightness to (medium | half){brightness:50}` - named entity `brightness` will be \"50\"\n* Rules\n    * `rule_name = rule body` can be referenced as `<rule_name>`\n* Slots\n    * `$slot` will be replaced by a list of sentences in the `replacements` argument of `intents_to_graph`\n\n#### Rules\n\nNamed rules can be added to your template file using the syntax:\n\n```ini\nrule_name = rule body\n```\n\nand then reference using `<rule_name>`. The body of a rule is a regular sentence, which may itself contain references to other rules.\n\nYou can refrence rules from different intents by prefixing the rule name with the intent name and a dot:\n\n```ini\n[Intent1]\nrule = a test\nthis is <rule>\n\n[Intent2]\nrule = this is\n<rule> <Intent1.rule>\n```\n\nIn the example above, `Intent2` uses its local `<rule>` as well as the `<rule>` from `Intent1`.\n\n#### Slots\n\nSlot names are prefixed with a dollar sign (`$`). When calling `intents_to_graph`, the `replacements` argument is a dictionary whose keys are slot names (with `$`) and whose values are lists of (parsed) `Sentence` objects. Each `$slot` will be replaced by the corresponding list of sentences, which may contain optional words, tags, rules, and other slots.\n\nFor example:\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[SetColor]\nset color to $color\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(\n    intents, replacements = {\n        \"$color\": [rhasspynlu.Sentence.parse(\"red | green | blue\")]\n    }\n)\n```\n\nwill replace `$color` with \"red\", \"green\", or \"blue\".\n\n## Intent Recognition\n\nAfter converting your sentence templates to a graph, you can recognize sentences. Assuming you have a `.ini` file like this:\n\n```\n[LightOn]\nturn on [the] (living room lamp | kitchen light){name}\n```\n\nYou can recognize sentences with:\n\n```python\nfrom pathlib import Path\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(Path(\"sentences.ini\"))\ngraph = rhasspynlu.intents_to_graph(intents)\n\nrhasspynlu.recognize(\"turn on living room lamp\", graph)\n```\n\nwill return a list of `Recognition` objects like:\n\n```\n[\n    Recognition(\n        intent=Intent(name='LightOn', confidence=1.0),\n        entities=[\n            Entity(\n                entity='name',\n                value='living room lamp',\n                raw_value='living room lamp',\n                start=8,\n                raw_start=8,\n                end=24,\n                raw_end=24,\n                tokens=['living', 'room', 'lamp'],\n                raw_tokens=['living', 'room', 'lamp']\n            )\n        ],\n        text='turn on living room lamp',\n        raw_text='turn on living room lamp',\n        recognize_seconds=0.00010710899914556649,\n        tokens=['turn', 'on', 'living', 'room', 'lamp'],\n        raw_tokens=['turn', 'on', 'living', 'room', 'lamp']\n    )\n]\n\n```\n\nAn empty list means that recognition has failed. You can easily convert `Recognition` objects to JSON:\n\n```python\n...\n\nimport json\n\nrecognitions = rhasspynlu.recognize(\"turn on living room lamp\", graph)\nif recognitions:\n    recognition_dict = recognitions[0].asdict()\n    print(json.dumps(recognition_dict))\n```\n\nYou can also pass an `intent_filter` function to `recognize` to return `True` only for intent names you want to include in the search.\n\n#### Tokens\n\nIf your sentence is tokenized by something other than whitespace, pass the list of tokens into `recognize` instead of a string.\n\n#### Recognition Fields\n\nThe `rhasspynlu.Recognition` object has the following fields:\n\n* `intent` - a `rhasspynlu.Intent` instance\n    * `name` - name of recognized intent\n    * `confidence` - number for 0-1, 1 being sure\n* `text` - substituted input text\n* `raw_text` - input text\n* `entities` - list of `rhasspynlu.Entity` objects\n    * `entity` - name of recognized entity (\"name\" in `(input:output){name}`)\n    * `value` - substituted value of recognized entity (\"output\" in `(input:output){name}`)\n    * `tokens` - list of words in `value`\n    * `start` - start index of `value` in `text`\n    * `end` - end index of `value` in `text` (exclusive)\n    * `raw_value` - value of recognized entity (\"input\" in `(input:output){name}`)\n    * `raw_tokens` - list of words in `raw_value`\n    * `raw_start` - start index of `raw_value` in `raw_text`\n    * `raw_end` - end index of `raw_value` in `raw_text` (exclusive)\n* `recognize_seconds` - seconds taken for `recognize`\n\n### Stop Words\n\nYou can pass a set of `stop_words` to `recognize`:\n\n```python\nrhasspynlu.recognize(\"turn on that living room lamp\", graph, stop_words=set([\"that\"]))\n```\n\nStop words in the input sentence will be skipped over if they don't match the graph.\n\n### Strict Recognition\n\nFor faster, but less flexible recognition, set `fuzzy` to `False`:\n\n```python\nrhasspynlu.recognize(\"turn on the living room lamp\", graph, fuzzy=False)\n```\n\nThis is at least twice as fast, but will fail if the sentence is not precisely present in the graph.\n\nStrict recognition also supports `stop_words` for a little added flexibility. If recognition without `stop_words` fails, a second attempt will be made using `stop_words`.\n\n### Converters\n\nValue conversions can be applied during recognition, such as converting the string \"10\" to the integer 10. Following a word, sequence, or tag name with \"!converter\" will run \"converter\" on the string value during `recognize`:\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[SetBrightness]\nset brightness to (one: hundred:100)!int\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(intents)\n\nrecognitions = rhasspynlu.recognize(\"set brightness to one hundred\", graph)\nassert recognitions[0].tokens[-1] == 100\n```\n\nConverters can be applied to tags/entities as well:\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[SetBrightness]\nset brightness to (one:1 | two:2){value!int}\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(intents)\n\nrecognitions = rhasspynlu.recognize(\"set brightness to two\", graph)\nassert recognitions[0].tokens[-1] == 2\n```\n\nThe following default converters are available in `rhasspynlu`:\n\n* int - convert to integer\n* float - convert to real\n* bool - convert to boolean\n* lower - lower-case\n* upper - upper-case\n\nYou may override these converters by passing a dictionary to the `converters` argument of `recognize`. To supply additional converters (instead of overriding), use `extra_converters`:\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[SetBrightness]\nset brightness to (one:1 | two:2){value!myconverter}\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(intents)\n\nrecognitions = rhasspynlu.recognize(\n    \"set brightness to two\",\n    graph,\n    extra_converters={\n        \"myconverter\": lambda *values: [int(v)**2 for v in values]\n    }\n)\nassert recognitions[0].tokens[-1] == 4\n```\n\nLastly, you can chain converters together with multiple \"!\":\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[SetBrightness]\nset brightness to (one:1 | two:2){value!int!cube}\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(intents)\n\nrecognitions = rhasspynlu.recognize(\n    \"set brightness to two\",\n    graph,\n    extra_converters={\n        \"cube\": lambda *values: [v**3 for v in values]\n    }\n)\nassert recognitions[0].tokens[-1] == 8\n```\n\n## ARPA Language Models\n\nYou can compute [ngram counts](https://en.wikipedia.org/wiki/N-gram) from a `rhasspynlu` graph, useful for generating [ARPA language models](https://cmusphinx.github.io/wiki/arpaformat/). These models can be used by speech recognition systems, such as [Pocketsphinx](https://github.com/cmusphinx/pocketsphinx), [Kaldi](https://kaldi-asr.org), and [Julius](https://github.com/julius-speech/julius).\n\n```python\nimport rhasspynlu\n\n# Load and parse\nintents = rhasspynlu.parse_ini(\n\"\"\"\n[SetColor]\nset light to (red | green | blue)\n\"\"\"\n)\n\ngraph = rhasspynlu.intents_to_graph(intents)\ncounts = rhasspynlu.get_intent_ngram_counts(\n    graph,\n    pad_start=\"<s>\",\n    pad_end=\"</s>\",\n    order=3\n)\n\n# Print counts by intent\nfor intent_name in counts:\n    print(intent_name)\n    for ngram, count in counts[intent_name].items():\n        print(ngram, count)\n\n    print(\"\")\n```\n\nwill print something like:\n\n```\nSetColor\n('<s>',) 3\n('set',) 3\n('<s>', 'set') 3\n('light',) 3\n('set', 'light') 3\n('<s>', 'set', 'light') 3\n('to',) 3\n('light', 'to') 3\n('set', 'light', 'to') 3\n('red',) 1\n('to', 'red') 1\n('light', 'to', 'red') 1\n('green',) 1\n('to', 'green') 1\n('light', 'to', 'green') 1\n('blue',) 1\n('to', 'blue') 1\n('light', 'to', 'blue') 1\n('</s>',) 3\n('red', '</s>') 1\n('green', '</s>') 1\n('blue', '</s>') 1\n('to', 'red', '</s>') 1\n('to', 'green', '</s>') 1\n('to', 'blue', '</s>') 1\n\n```\n\n### Opengrm\n\nIf you have the [Opengrm](http://www.opengrm.org/twiki/bin/view/GRM/NGramLibrary) command-line tools in your `PATH`, you can use `rhasspynlu` to generate language models in the [ARPA format](https://cmusphinx.github.io/wiki/arpaformat/).\n\nThe `graph_to_fst` and `fst_to_arpa` functions are used to convert between formats. Calling `fst_to_arpa` requires the following binaries to be present in your `PATH`:\n\n* `fstcompile` (from [OpenFST](http://www.openfst.org))\n* `ngramcount`\n* `ngrammake`\n* `ngrammerge`\n* `ngramprint`\n* `ngramread`\n\nExample:\n\n```python\n# Convert to FST\ngraph_fst = rhasspynlu.graph_to_fst(graph)\n\n# Write FST and symbol text files\ngraph_fst.write(\"my_fst.txt\", \"input_symbols.txt\", \"output_symbols.txt\")\n\n# Compile and convert to ARPA language model\nrhasspynlu.fst_to_arpa(\n    \"my_fst.txt\",\n    \"input_symbols.txt\",\n    \"output_symbols.txt\",\n    \"my_arpa.lm\"\n)\n```\n\nYou can now use `my_arpa.lm` in any speech recognizer that accepts ARPA-formatted language models.\n\n### Language Model Mixing\n\nIf you have an existing language model that you'd like to mix with Rhasspy voice commands, you will first need to convert it to an FST:\n\n```python\nrhasspynlu.fst_to_arpa(\"existing_arpa.lm\", \"existing_arpa.fst\")\n```\n\nNow when you call `fst_to_arpa`, make sure to provide the `base_fst_weight` argument. This is a tuple with the path to your existing ARPA FST and a mixture weight between 0 and 1. A weight of 0.05 means that the base language model will receive 5% of the overall probability mass in the language model. The rest of the mass will be given to your custom voice commands.\n\nExample:\n\n```python\nrhasspynlu.fst_to_arpa(\n    \"my_fst.txt\",\n    \"input_symbols.txt\",\n    \"output_symbols.txt\",\n    \"my_arpa.lm\",\n    base_fst_weight=(\"existing_arpa.fst\", 0.05)\n)\n```\n\n## Command Line Usage\n\nThe `rhasspynlu` module can be run directly to convert `sentences.ini` files into JSON graphs or FST text files:\n\n```bash\npython3 -m rhasspynlu sentences.ini > graph.json\n```\n\nYou can pass multiple `.ini` files as arguments, and they will be combined. Adding a `--fst` argument will write out FST text files instead:\n\n```bash\npython3 -m rhasspynlu sentences.ini --fst\n```\n\nThis will output three files in the current directory:\n\n* `fst.txt` - finite state transducer as text\n* `fst.isymbols.txt` - input symbols\n* `fst.osymbols.txt` - output symbols\n\nThese file names can be changed with the `--fst-text`, `--fst-isymbols`, and `--fst-osymbols` arguments, respectively.\n\nCompile to a binary FST using `fstcompile` (from [OpenFST](http://www.openfst.org)) with:\n\n```bash\nfstcompile \\\n    --isymbols=fst.isymbols.txt \\\n    --osymbols=fst.osymbols.txt \\\n    --keep_isymbols=1 \\\n    --keep_osymbols=1 \\\n    fst.txt \\\n    out.fst\n```\n\n## Word Pronunciations\n\nMethods for loading and using phonetic pronunciation dictionaries are provided in `rhasspynlu.g2p` (\"g2p\" stands for \"grapheme to phoneme\").\n\nDictionaries are expected in the same format as the [CMU Pronouncing Dictionary](https://github.com/cmusphinx/cmudict), which is simply one word per line with whitespace separating words and phonemes:\n\n```\nyawn Y AO N\ntest T EH S T\nsay S EY\nwho HH UW\nbee B IY\nazure AE ZH ER\nread R EH D\nread(2) R IY D\n```\n\nWhen multiple pronunciations are available for a word (like \"read\" in the previous example), a `(N)` can be suffixed to the word.\n\nYou can load a phonetic dictionary into a Python dictionary with `rhasspynlu.g2p.read_pronunciations`:\n\n```python\nimport rhasspynlu.g2p\n\nwith open(\"/path/to/file.dict\", \"r\") as dict_file:\n    pronunciations = rhasspynlu.g2p.read_pronunciations(dict_file)\n\nassert pronunciations == {\n    \"yawn\": [[\"Y\", \"AO\", \"N\"]],\n    \"test\": [[\"T\", \"EH\", \"S\", \"T\"]],\n    \"say\": [[\"S\", \"EY\"]],\n    \"who\": [[\"HH\", \"UW\"]],\n    \"bee\": [[\"B\", \"IY\"]],\n    \"azure\": [[\"AE\", \"ZH\", \"ER\"]],\n    \"read\": [[\"R\", \"EH\", \"D\"], [\"R\", \"IY\", \"D\"]],\n}\n```\n\nSee [voice2json profiles](https://github.com/synesthesiam/voice2json-profiles) for pre-built phonetic dictionaries.\n\n### Guessing Pronunciations\n\nThe `rhasspynlu.g2p.guess_pronunciations` function uses [Phonetisaurus](https://github.com/AdolfVonKleist/Phonetisaurus) and a pre-trained grapheme to phoneme model to guess pronunciations for unknown words. You will need `phonetisaurus-apply` in your `$PATH` and the pre-trained model (`g2p.fst`) available:\n\n```python\nimport rhasspynlu.g2p\n\nguesses = rhasspynlu.g2p.guess_pronunciations(\n    [\"moogle\", \"ploop\"], \"/path/to/g2p.fst\", num_guesses=1\n)\n\nprint(list(guesses))\n\n# Something like: [\n#   ('moogle', ['M', 'UW', 'G', 'AH', 'L']),\n#   ('ploop', ['P', 'L', 'UW', 'P'])\n# ]\n```\n\nSee [voice2json profiles](https://github.com/synesthesiam/voice2json-profiles) for pre-trained g2p models.\n\n### Sounds Like Pronunciations\n\nRhasspy NLU supports an alternative way of specifying word pronunciations. Instead of specifying phonemes directly, you can describe how a word should be pronounced by referencing other words:\n\n```\nunknown_word1 known_word1 [known_word2] ...\n...\n```\n\nFor example, the singer [Beyoncé](https://www.beyonce.com/) sounds like a combination of the words \"bee yawn say\":\n\n```\nbeyoncé bee yawn say\n```\n\nThe `rhasspynlu.g2p.load_sounds_like` function will parse this text and, when given an existing pronunciation dictionary, generate a new pronunciation:\n\n```python\nimport io\n\nimport rhasspynlu.g2p\n\n# Load existing dictionary\npronunciations = rhasspynlu.g2p.read_pronunciations(\"/path/to/file.dict\")\n\nsounds_like = \"\"\"\nbeyoncé bee yawn say\n\"\"\"\n\nwith io.StringIO(sounds_like) as f:\n    rhasspynlu.g2p.load_sounds_like(f, pronunciations)\n\nprint(pronunciations[\"beyoncé\"])\n\n# Something like: [['B', 'IY', 'Y', 'AO', 'N', 'S', 'EY']]\n```\n\nYou may reference a specific pronunciation for a known word using the `word(N)` syntax, where `N` is 1-based. Pronunciations are loaded in line order, so the order is predictable. For example, `read(2)` will reference the second pronunciation of the word \"read\". Without an `(N)`, all pronunciations found will be used.\n\n#### Phoneme Literals\n\nYou can interject phonetic chunks into these pronunciations too. For example, the word \"hooiser\" sounds like \"who\" and the \"-zure\" in \"azure\":\n\n```\nhooiser who /Z 3/\n```\n\nText between slashes (`/`) will be interpreted as phonemes in the configured speech system.\n\n#### Word Segments\n\nIf a grapheme-to-phoneme alignment corupus is available, segments of words can also be used for pronunciations. Using the \"hooiser\" example above, we can replace the phonemes with:\n\n```\nhooiser who a>zure<\n```\n\nThis will combine the pronunciation of \"who\" from the current phonetic dictionaries (`base_dictionary.txt` and `custom_words.txt`) and the \"-zure\" from the word \"azure\".\n\nThe brackets point `>at<` the segment of the word that you want to contribute to the pronunciation. This is accomplished using a grapheme-to-phoneme alignment corpus generated with [phonetisaurus\n](https://github.com/AdolfVonKleist/Phonetisaurus) and a pre-built phonetic dictionary. In the `a>zure<` example, the word \"azure\" is located in the alignment corpus, and the output phonemes from the phonemes \"zure\" in it are used.\n\n```python\nimport io\n\nimport rhasspynlu.g2p\n\n# Load existing dictionary\npronunciations = rhasspynlu.g2p.read_pronunciations(\"/path/to/file.dict\")\n\n# Example alignment corpus:\n# a}AE z}ZH u|r}ER e}_\nalignment = rhasspynlu.g2p.load_g2p_corpus(\"/path/to/g2p.corpus\")\n\nsounds_like = \"\"\"\nhooiser who a>zure<\n\"\"\"\n\nwith io.StringIO(sounds_like) as f:\n    rhasspynlu.g2p.load_sounds_like(\n        f, pronunciations, g2p_alignment=alignment\n    )\n\nprint(pronunciations[\"hooiser\"])\n\n# Something like [[\"HH\", \"UW\", \"ZH\", \"ER\"]]\n```\n\nSee [voice2json profiles](https://github.com/synesthesiam/voice2json-profiles) for g2p alignment corpora.","description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/rhasspy/rhasspy-nlu","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"rhasspy-nlu","package_url":"https://pypi.org/project/rhasspy-nlu/","platform":"","project_url":"https://pypi.org/project/rhasspy-nlu/","project_urls":{"Homepage":"https://github.com/rhasspy/rhasspy-nlu"},"provides_extra":null,"release_url":"https://pypi.org/project/rhasspy-nlu/0.4.0/","requires_dist":null,"requires_python":">=3.7","summary":"","version":"0.4.0","yanked":false,"yanked_reason":null},"last_serial":10732842,"releases":{"0.1":[{"comment_text":"","digests":{"blake2b_256":"3ddc941f5bb7ae4d3dba9a1800da2484ba639ed891e836317823c7a912cf12f8","md5":"854f7d238d9d57c8371506f040d1f98b","sha256":"ed7f14a3da28e448135a47131ae3e2ff771ce7c887845f14c7f46800faad0369"},"downloads":-1,"filename":"rhasspy-nlu-0.1.tar.gz","has_sig":false,"md5_digest":"854f7d238d9d57c8371506f040d1f98b","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":20736,"upload_time":"2019-12-10T21:43:14","upload_time_iso_8601":"2019-12-10T21:43:14.123534Z","url":"https://files.pythonhosted.org/packages/3d/dc/941f5bb7ae4d3dba9a1800da2484ba639ed891e836317823c7a912cf12f8/rhasspy-nlu-0.1.tar.gz","yanked":false,"yanked_reason":null}],"0.1.1":[{"comment_text":"","digests":{"blake2b_256":"8d76d033ee6550287163d19eeffdd0105987df6b5ffb8617df3533c51eac6b9f","md5":"002b8c9b6951190955c7ef29f78cdd09","sha256":"68e733b2f59625421c41d0b02bcf1c70a21aed90312711eec556f302295efedc"},"downloads":-1,"filename":"rhasspy-nlu-0.1.1.tar.gz","has_sig":false,"md5_digest":"002b8c9b6951190955c7ef29f78cdd09","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":24828,"upload_time":"2019-12-11T22:11:52","upload_time_iso_8601":"2019-12-11T22:11:52.574310Z","url":"https://files.pythonhosted.org/packages/8d/76/d033ee6550287163d19eeffdd0105987df6b5ffb8617df3533c51eac6b9f/rhasspy-nlu-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"0.1.10":[{"comment_text":"","digests":{"blake2b_256":"576f92183c3738692d4e633d6c627c6e0f6a7ec3d9fe0f7fa1ce8875bc054f77","md5":"b632f158b4b30ae4a2819fd620d457f1","sha256":"d9b5eead55b4ae458bbd3c2eb1c7f0c36f59cafcf8d3df39a2ab592a94416028"},"downloads":-1,"filename":"rhasspy-nlu-0.1.10.tar.gz","has_sig":false,"md5_digest":"b632f158b4b30ae4a2819fd620d457f1","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":47179,"upload_time":"2020-06-05T13:02:03","upload_time_iso_8601":"2020-06-05T13:02:03.296957Z","url":"https://files.pythonhosted.org/packages/57/6f/92183c3738692d4e633d6c627c6e0f6a7ec3d9fe0f7fa1ce8875bc054f77/rhasspy-nlu-0.1.10.tar.gz","yanked":false,"yanked_reason":null}],"0.1.2":[{"comment_text":"","digests":{"blake2b_256":"f9f6c1fb530b2de105155c8d1b381d463e92c9ee15b38b1cb1fe8036023eb418","md5":"b17ec74602f8a7b46393a72ccabaf25f","sha256":"f0428284f2bbf159d03db3d2e9b93c09b0c29c6370bf7efe9216aa87fa588b14"},"downloads":-1,"filename":"rhasspy-nlu-0.1.2.tar.gz","has_sig":false,"md5_digest":"b17ec74602f8a7b46393a72ccabaf25f","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":21810,"upload_time":"2019-12-15T19:23:43","upload_time_iso_8601":"2019-12-15T19:23:43.435437Z","url":"https://files.pythonhosted.org/packages/f9/f6/c1fb530b2de105155c8d1b381d463e92c9ee15b38b1cb1fe8036023eb418/rhasspy-nlu-0.1.2.tar.gz","yanked":false,"yanked_reason":null}],"0.1.3":[{"comment_text":"","digests":{"blake2b_256":"e4c54cd19c8099d8acc92c68f8d114462d552d5a84bb57c815c6b058e9791813","md5":"39ef158c549c398b564b6ecc2bc73bcb","sha256":"ba0ecdf610b116b9a57c9190883daf3b0956d3138669971981b5b6ffa835c28a"},"downloads":-1,"filename":"rhasspy-nlu-0.1.3.tar.gz","has_sig":false,"md5_digest":"39ef158c549c398b564b6ecc2bc73bcb","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":22925,"upload_time":"2019-12-21T20:51:18","upload_time_iso_8601":"2019-12-21T20:51:18.679399Z","url":"https://files.pythonhosted.org/packages/e4/c5/4cd19c8099d8acc92c68f8d114462d552d5a84bb57c815c6b058e9791813/rhasspy-nlu-0.1.3.tar.gz","yanked":false,"yanked_reason":null}],"0.1.4":[{"comment_text":"","digests":{"blake2b_256":"72c2717721bf11392fa9ebf3eef80db4d18e18a48d4f144bd0385e7f17d7a096","md5":"ef8d6c342085abaec45991018a37ee79","sha256":"9225447c407adf3e8c86a1c5d2fd195a3503fe1f397f36a4115fd493da740b6b"},"downloads":-1,"filename":"rhasspy-nlu-0.1.4.tar.gz","has_sig":false,"md5_digest":"ef8d6c342085abaec45991018a37ee79","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":30710,"upload_time":"2020-01-03T16:46:24","upload_time_iso_8601":"2020-01-03T16:46:24.641822Z","url":"https://files.pythonhosted.org/packages/72/c2/717721bf11392fa9ebf3eef80db4d18e18a48d4f144bd0385e7f17d7a096/rhasspy-nlu-0.1.4.tar.gz","yanked":false,"yanked_reason":null}],"0.1.4.1":[{"comment_text":"","digests":{"blake2b_256":"1cdb57cf2f9de50c437530dbbd73451fc620024fab374aef814aadbd2e76b764","md5":"5927257b82b5c31d59850daff02c7bd1","sha256":"3cce4dfcd2aeab4f9ef637a90e3e594b5440d43f90758aabe53d6e70773a1565"},"downloads":-1,"filename":"rhasspy-nlu-0.1.4.1.tar.gz","has_sig":false,"md5_digest":"5927257b82b5c31d59850daff02c7bd1","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":26805,"upload_time":"2020-01-04T21:40:43","upload_time_iso_8601":"2020-01-04T21:40:43.625859Z","url":"https://files.pythonhosted.org/packages/1c/db/57cf2f9de50c437530dbbd73451fc620024fab374aef814aadbd2e76b764/rhasspy-nlu-0.1.4.1.tar.gz","yanked":false,"yanked_reason":null}],"0.1.5":[{"comment_text":"","digests":{"blake2b_256":"16cb2a740c6c8d2ee67f9999387a97824666f8926619fbf9bc8c99623eb17cd7","md5":"3dbed48e96fe80bbd498d17f9077344d","sha256":"1b9bbe8fac980b33a2498bcfc8ec5033b4a2327ba8034092f13d731bddd5c36e"},"downloads":-1,"filename":"rhasspy-nlu-0.1.5.tar.gz","has_sig":false,"md5_digest":"3dbed48e96fe80bbd498d17f9077344d","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":28933,"upload_time":"2020-01-20T19:45:29","upload_time_iso_8601":"2020-01-20T19:45:29.921067Z","url":"https://files.pythonhosted.org/packages/16/cb/2a740c6c8d2ee67f9999387a97824666f8926619fbf9bc8c99623eb17cd7/rhasspy-nlu-0.1.5.tar.gz","yanked":false,"yanked_reason":null}],"0.1.6":[{"comment_text":"","digests":{"blake2b_256":"a3332f9ef0e4c410a669de0b2b4c8f01d1a765fa09aaa185c1368c8b5db3ee54","md5":"4302fc7877b2964e28f6af2a79c4b7d9","sha256":"066a7b33ef1f44295db98f0dd02ca3837c1fe10ca4d256eec8435593ce858064"},"downloads":-1,"filename":"rhasspy-nlu-0.1.6.tar.gz","has_sig":false,"md5_digest":"4302fc7877b2964e28f6af2a79c4b7d9","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":39109,"upload_time":"2020-02-06T15:26:55","upload_time_iso_8601":"2020-02-06T15:26:55.967139Z","url":"https://files.pythonhosted.org/packages/a3/33/2f9ef0e4c410a669de0b2b4c8f01d1a765fa09aaa185c1368c8b5db3ee54/rhasspy-nlu-0.1.6.tar.gz","yanked":false,"yanked_reason":null}],"0.1.8":[{"comment_text":"","digests":{"blake2b_256":"aa9959ce646014d766e4c017b259951e657fbd6a8dd675fdaeaf4666bbd2fdf4","md5":"32c335f436ac91770223713c56ed9644","sha256":"e9421f9c7c61802ab1a4969ee01b9482b9b402f28cf96351ad6751a92c140bb6"},"downloads":-1,"filename":"rhasspy-nlu-0.1.8.tar.gz","has_sig":false,"md5_digest":"32c335f436ac91770223713c56ed9644","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":43553,"upload_time":"2020-04-24T14:30:34","upload_time_iso_8601":"2020-04-24T14:30:34.925839Z","url":"https://files.pythonhosted.org/packages/aa/99/59ce646014d766e4c017b259951e657fbd6a8dd675fdaeaf4666bbd2fdf4/rhasspy-nlu-0.1.8.tar.gz","yanked":false,"yanked_reason":null}],"0.1.9":[{"comment_text":"","digests":{"blake2b_256":"0c9daa60647fac27453162c1e32d8b3599e3b80203c2aed2e63bc6be39b57cfa","md5":"54a198ff0a1b0110ff0cf5497b49c052","sha256":"1f02771861730db369d08d4af102f4c619204c6e12255081b0aead949f9b5d75"},"downloads":-1,"filename":"rhasspy-nlu-0.1.9.tar.gz","has_sig":false,"md5_digest":"54a198ff0a1b0110ff0cf5497b49c052","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46982,"upload_time":"2020-06-02T14:28:15","upload_time_iso_8601":"2020-06-02T14:28:15.103023Z","url":"https://files.pythonhosted.org/packages/0c/9d/aa60647fac27453162c1e32d8b3599e3b80203c2aed2e63bc6be39b57cfa/rhasspy-nlu-0.1.9.tar.gz","yanked":false,"yanked_reason":null}],"0.2.0":[{"comment_text":"","digests":{"blake2b_256":"c99936ea90fdc66a98945012504a50c4ec049523e853167cadfdc8c7c472872e","md5":"bf34ef26029e1e98f11b7a11bf7996b0","sha256":"6ae9d56146a7db5f55b3aecbdc667d628a2c75c610818c011bca4e8f85c3681d"},"downloads":-1,"filename":"rhasspy-nlu-0.2.0.tar.gz","has_sig":false,"md5_digest":"bf34ef26029e1e98f11b7a11bf7996b0","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":47946,"upload_time":"2020-06-24T19:07:17","upload_time_iso_8601":"2020-06-24T19:07:17.046596Z","url":"https://files.pythonhosted.org/packages/c9/99/36ea90fdc66a98945012504a50c4ec049523e853167cadfdc8c7c472872e/rhasspy-nlu-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"0.3.0":[{"comment_text":"","digests":{"blake2b_256":"437a57bf7e5d09731ca2388b7ceadd0d17e0f91e57cca73693e8266ca714793b","md5":"68e61a5a92254ae3072f7ed6a7be0c05","sha256":"1adc3f30f3a1a4c94494012959608a3121be304c1586bc4215c56dafe2782e7a"},"downloads":-1,"filename":"rhasspy-nlu-0.3.0.tar.gz","has_sig":false,"md5_digest":"68e61a5a92254ae3072f7ed6a7be0c05","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":50053,"upload_time":"2020-07-17T20:17:55","upload_time_iso_8601":"2020-07-17T20:17:55.262309Z","url":"https://files.pythonhosted.org/packages/43/7a/57bf7e5d09731ca2388b7ceadd0d17e0f91e57cca73693e8266ca714793b/rhasspy-nlu-0.3.0.tar.gz","yanked":false,"yanked_reason":null}],"0.3.1":[{"comment_text":"","digests":{"blake2b_256":"e0fde81177e0549da3500123534a91aa34f258bcfb85716686501a3f8ba468ee","md5":"4e1940a58b7f1277684a2280aa7614b7","sha256":"f4caf66651e8724ff13e5af5feadd8ddb44e0409c1837f74585bbd4e173369e6"},"downloads":-1,"filename":"rhasspy-nlu-0.3.1.tar.gz","has_sig":false,"md5_digest":"4e1940a58b7f1277684a2280aa7614b7","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":50742,"upload_time":"2020-07-24T15:45:28","upload_time_iso_8601":"2020-07-24T15:45:28.782905Z","url":"https://files.pythonhosted.org/packages/e0/fd/e81177e0549da3500123534a91aa34f258bcfb85716686501a3f8ba468ee/rhasspy-nlu-0.3.1.tar.gz","yanked":false,"yanked_reason":null}],"0.3.3":[{"comment_text":"","digests":{"blake2b_256":"3f388b1fe5306af7a361913dc255cd963158c21e545fc84684487564e4b13da3","md5":"5d39f86c163ee5b380643ed642eee287","sha256":"5634bf8e7486cc201f70f0155ac0daec90f92a5d5d6d02ed4c49ceae50177698"},"downloads":-1,"filename":"rhasspy-nlu-0.3.3.tar.gz","has_sig":false,"md5_digest":"5d39f86c163ee5b380643ed642eee287","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":50918,"upload_time":"2020-10-03T14:53:39","upload_time_iso_8601":"2020-10-03T14:53:39.659460Z","url":"https://files.pythonhosted.org/packages/3f/38/8b1fe5306af7a361913dc255cd963158c21e545fc84684487564e4b13da3/rhasspy-nlu-0.3.3.tar.gz","yanked":false,"yanked_reason":null}],"0.4.0":[{"comment_text":"","digests":{"blake2b_256":"7eb6715c011b5fd00aad22752a4c8d6598d629a9385f2dbd569a67d502be69c0","md5":"2c2e81d8b473bfac545cf9817cad9da3","sha256":"0e75b81bdc373031e8484826dc4f99643ae832fa1f05c589f757d493896b48c2"},"downloads":-1,"filename":"rhasspy-nlu-0.4.0.tar.gz","has_sig":false,"md5_digest":"2c2e81d8b473bfac545cf9817cad9da3","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":52374,"upload_time":"2021-06-24T14:18:39","upload_time_iso_8601":"2021-06-24T14:18:39.882018Z","url":"https://files.pythonhosted.org/packages/7e/b6/715c011b5fd00aad22752a4c8d6598d629a9385f2dbd569a67d502be69c0/rhasspy-nlu-0.4.0.tar.gz","yanked":false,"yanked_reason":null}]},"urls":[{"comment_text":"","digests":{"blake2b_256":"7eb6715c011b5fd00aad22752a4c8d6598d629a9385f2dbd569a67d502be69c0","md5":"2c2e81d8b473bfac545cf9817cad9da3","sha256":"0e75b81bdc373031e8484826dc4f99643ae832fa1f05c589f757d493896b48c2"},"downloads":-1,"filename":"rhasspy-nlu-0.4.0.tar.gz","has_sig":false,"md5_digest":"2c2e81d8b473bfac545cf9817cad9da3","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":52374,"upload_time":"2021-06-24T14:18:39","upload_time_iso_8601":"2021-06-24T14:18:39.882018Z","url":"https://files.pythonhosted.org/packages/7e/b6/715c011b5fd00aad22752a4c8d6598d629a9385f2dbd569a67d502be69c0/rhasspy-nlu-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}
